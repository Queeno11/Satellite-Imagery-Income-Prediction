{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############      Configuración      ##############\n",
    "import sys\n",
    "sys.path.append('..')  # Add the parent directory to the sys.path\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "env = dotenv_values(\"/mnt/d/Maestría/Tesis/Repo/scripts/globals.env\")\n",
    "\n",
    "path_proyecto = env[\"PATH_PROYECTO\"]\n",
    "path_datain = env[\"PATH_DATAIN\"]\n",
    "path_dataout = env[\"PATH_DATAOUT\"]\n",
    "path_out_imgs = r\"/mnt/e/Tesis Maestría/imagenes\"\n",
    "path_scripts = env[\"PATH_SCRIPTS\"]\n",
    "path_satelites = env[\"PATH_SATELITES\"]\n",
    "path_logs = env[\"PATH_LOGS\"]\n",
    "path_outputs = env[\"PATH_OUTPUTS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import earthpy.plot as ep\n",
    "import build_dataset as bd\n",
    "import utils\n",
    "import geopandas as gpd\n",
    "import shapely\n",
    "import skimage\n",
    "import folium\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "raster_size = 58.435144 - 58.435139 # In epsg 4326 degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, extents = bd.load_satellite_datasets()\n",
    "icpag = bd.load_icpag_dataset()\n",
    "icpag = bd.assign_links_to_datasets(icpag, extents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imagenes de Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import skimage\n",
    "import cv2\n",
    "import os\n",
    "img_folders = os.listdir(path_out_imgs)\n",
    "img_folders = [folder for folder in img_folders if \"train\" in folder]\n",
    "\n",
    "fig, axs = plt.subplots(4,7, figsize=(5*7, 5*4))\n",
    "for row, folder in enumerate(img_folders):\n",
    "\n",
    "    imgs = os.listdir(f\"{path_out_imgs}/{folder}\")\n",
    "    show_imgs = random.sample(imgs, 7)\n",
    "\n",
    "    for col, im_path in enumerate(show_imgs):\n",
    "\n",
    "        im = np.load(f\"{path_out_imgs}/{folder}/{im_path}\")\n",
    "        im = np.moveaxis(im, 0, 2)\n",
    "        im = im[:,:,:3]\n",
    "        # Equalize hist\n",
    "        im = skimage.exposure.equalize_hist(im)\n",
    "        im = cv2.resize(im, (128, 128))\n",
    "\n",
    "        axs[row][col].imshow(im[:,:,:3])\n",
    "        axs[row][col].set_axis_off()\n",
    "        axs[row][col].set_title(f\"{folder}_{row}\")\n",
    "        \n",
    "# Remove axis lables\n",
    "plt.axis(\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training/validaton_by_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_repo = r\"/mnt/d/Maestría/Tesis/Repo\"\n",
    "# path_repo = r\"D:/Maestría/Tesis/Repo\"\n",
    "path_outputs = f\"{path_repo}/outputs\"\n",
    "path_dataout = f\"{path_repo}/data/data_out\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models =[\n",
    "    \"mobnet_v3_size128_tiles1_sample5\",\n",
    "    # \"mobnet_v3_size256_tiles1_sample1\",\n",
    "    # \"mobnet_v3_size512_tiles1_sample1\",\n",
    "    # \"mobnet_v3_size128_tiles2_sample20\",\n",
    "]\n",
    "\n",
    "old_models = { \n",
    "        'mobnet_v3_size128_tiles1_sample1':\n",
    "            [\n",
    "                'mobnet_v3_20230908-203439',\n",
    "                'mobnet_v3_20230909-020833',\n",
    "                'mobnet_v3_20230909-121048',\n",
    "                'mobnet_v3_20230909-153231',\n",
    "                'mobnet_v3_20230909-202517',\n",
    "                'mobnet_v3_20230909-213040',\n",
    "                'mobnet_v3_20230910-130103',\n",
    "                'mobnet_v3_20230911-092415',\n",
    "                'mobnet_v3_20230911-231611',\n",
    "                'mobnet_v3_20230912-012855',\n",
    "            ],\n",
    "        'mobnet_v3_size256_tiles1_sample1':\n",
    "            [       \n",
    "                'mobnet_v3_20230914-215006',\n",
    "                'mobnet_v3_20230913-200010',\n",
    "            ],      \n",
    "        'mobnet_v3_size512_tiles1_sample1':\n",
    "            [\n",
    "                'mobnet_v3_20230915-122541',\n",
    "                'mobnet_v3_20230916-124818',\n",
    "            ],\n",
    "        'mobnet_v3_size128_tiles2_sample20':\n",
    "            [\n",
    "                'mobnet_v3_20230918-192554',\n",
    "                'mobnet_v3_20230918-231134',\n",
    "                'mobnet_v3_20230919-104912',\n",
    "                'mobnet_v3_20230919-234505',\n",
    "                'mobnet_v3_20230920-131123',\n",
    "                'mobnet_v3_20230920-180458',\n",
    "                'mobnet_v3_20230920-194725',\n",
    "            ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "import numpy as np\n",
    "\n",
    "# First, upload experiment to Tensorboard:\n",
    "# \n",
    "# Extract data from TB\n",
    "experiment_id = \"CwPHXf5GQ9qdvTQcZoNyow\"\n",
    "experiment = tb.data.experimental.ExperimentFromDev(experiment_id)\n",
    "df = experiment.get_scalars()\n",
    "\n",
    "for kind in [\"train\", \"validation\"]:\n",
    "    # Keep only train values\n",
    "    base = df[df.run.str.contains(f'{kind}') & (df.tag == 'epoch_loss')]\n",
    "    base['run'] = base.run.str.replace(f\"/{kind}\", \"\")\n",
    "\n",
    "    # Filter model\n",
    "    models_by_date = {\n",
    "        'mobnet_v3_size128_tiles1_sample5':[\"\"]\n",
    "    }\n",
    "\n",
    "    base['model'] = np.nan\n",
    "    for model, names in models_by_date.items():\n",
    "        for name in names:\n",
    "            base.loc[base.run.str.contains(name), 'model'] = model\n",
    "            \n",
    "    # Reshape data\n",
    "    plot_data = base[~base.model.isna()]\\\n",
    "        .drop_duplicates(subset=['model','step'], keep='first')\\\n",
    "        .pivot(index='step', columns='model', values='value')\n",
    "        \n",
    "    # Export data\n",
    "    plot_data.to_csv(f\"{path_repo}/data/data_out/{kind}_by_epoch.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# True Mean Squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "path_repo = r\"/mnt/d/Maestría/Tesis/Repo\"\n",
    "# path_repo = r\"D:/Maestría/Tesis/Repo\"\n",
    "path_outputs = f\"{path_repo}/outputs\"\n",
    "path_dataout = f\"{path_repo}/data/data_out\"\n",
    "\n",
    "def get_model_results(modelname):\n",
    "    \n",
    "    folder = f\"{path_repo}/data/data_out/models_by_epoch/{modelname}\"\n",
    " \n",
    "    # Get train dataset\n",
    "    train_data = pd.read_csv(rf\"{path_dataout}/train_by_epoch.csv\")\n",
    "    mse_train_df = train_data[[modelname]]\n",
    "    # TODO: Calcular el R2\n",
    "    mse_train_df = mse_train_df.reset_index().rename(columns={'index':'epoch', modelname:'mse_train'})\n",
    "\n",
    "    # Get validation (test by each image) dataset\n",
    "    test2_data = pd.read_csv(rf\"{path_dataout}/validation_by_epoch.csv\")\n",
    "    mse_test2_df = test2_data[[modelname]]\n",
    "    # TODO: Calcular el R2\n",
    "    mse_test2_df = mse_test2_df.reset_index().rename(columns={'index':'epoch', modelname:'mse_test_imgs'})\n",
    "\n",
    "    # Get test dataset\n",
    "    mse_test_df = pd.DataFrame()\n",
    "    for epoch in tqdm(range(0, 200)):\n",
    "\n",
    "        df = pd.read_csv(f\"{folder}/{modelname}_{epoch}.csv\")\n",
    "        mse = df.groupby(\"link\").sq_error.mean().mean()\n",
    "\n",
    "        mse_test_df.at[epoch, 'mse_test_rc'] = mse\n",
    "        mse_test_df.at[epoch, 'epoch'] = epoch    \n",
    "    \n",
    "    # Merge both df\n",
    "    mse_df = mse_train_df.merge(mse_test_df, on='epoch')\n",
    "    mse_df = mse_df.merge(mse_test2_df, on='epoch')\n",
    "\n",
    "    return mse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mse_over_epochs(mse_df, modelname, metric=\"mse\", save=False):\n",
    "    import plotly.express as px\n",
    "    from plotly import graph_objects as go\n",
    "\n",
    "    plot_df = mse_df.melt(id_vars='epoch', value_vars=['mse_test_imgs', 'mse_test_rc','mse_train'])\n",
    "\n",
    "    # Plot\n",
    "    fig = px.line(plot_df, x=\"epoch\", y=\"value\", color=\"variable\", title='True Mean Squared Error over epochs')\n",
    "    fig.update_yaxes(range=[0, 1])\n",
    "\n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=1280,\n",
    "        height=720,)\n",
    "\n",
    "    if save:\n",
    "        fig.write_image(f\"{path_outputs}/mse_best_prediction_{modelname}.png\")\n",
    "\n",
    "    return fig\n",
    "    \n",
    "def plot_predictions_vs_real(mse_df, modelname, quantiles=False, last_training=False, save=False):\n",
    "    import plotly.express as px\n",
    "    from plotly import graph_objects as go\n",
    "\n",
    "    folder = f\"{path_repo}/data/data_out/models_by_epoch/{modelname}\"\n",
    "    \n",
    "    # Select best epoch... ¿Is this correct?       \n",
    "    best_case_epoch = mse_df.loc[mse_df[\"mse_test_rc\"]==mse_df[\"mse_test_rc\"].min()].index.values[0]\n",
    "\n",
    "    if last_training:\n",
    "        best_case_epoch = 199\n",
    "        \n",
    "    # Open dataset\n",
    "    best_case = pd.read_csv(\n",
    "        rf\"{folder}/{modelname}_{best_case_epoch}.csv\"\n",
    "        )\n",
    "    best_case = best_case.groupby(\"link\")[['real_value', 'mean_prediction']].mean().reset_index()\n",
    "    if quantiles:\n",
    "        best_case['real_value'] = pd.qcut(best_case['real_value'], 100, labels=False)\n",
    "        best_case['mean_prediction'] = pd.qcut(best_case['mean_prediction'], 100, labels=False)\n",
    "        axis_range = [0, 100]\n",
    "        title = f\"{modelname} - cuantiles\"\n",
    "    else:\n",
    "        axis_range = [-2, 2]\n",
    "        title = f\"{modelname} - niveles\"\n",
    "        \n",
    "    import seaborn as sns\n",
    "    fig = px.scatter(best_case, x=\"real_value\", y=\"mean_prediction\", hover_data=[\"link\"],\n",
    "                     title=title)\n",
    "    fig.update_yaxes(range=axis_range)\n",
    "    fig.update_xaxes(range=axis_range)\n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=800,\n",
    "        height=800,)\n",
    "\n",
    "    # Add 45° line\n",
    "    line_fig = go.Figure(data=go.Scatter(x=best_case['real_value'], y=best_case['real_value'], mode='lines', name='45°'))\n",
    "    fig.add_trace(line_fig.data[0])\n",
    "\n",
    "    if save:\n",
    "        if quantiles:\n",
    "            fig.write_image(f\"{path_outputs}/prediction_vs_real_best_prediction_{modelname}_q.png\")\n",
    "        else:\n",
    "            fig.write_image(f\"{path_outputs}/prediction_vs_real_best_prediction_{modelname}.png\")\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_over_epochs(modelnames, metric=\"mse\", save=True):\n",
    "    import plotly.express as px\n",
    "    from plotly import graph_objects as go\n",
    "\n",
    "    plot_data = []\n",
    "    for modelname in modelnames:\n",
    "        # Get data\n",
    "        mse_df = get_model_results(modelname)\n",
    "\n",
    "        # Prepare dataset for plot\n",
    "        var_x = icpag.groupby(\"link\")['var'].first().var()\n",
    "        mse_df['r2'] = 1 - mse_df.mse / var_x\n",
    "        mse_df['smoothed_mse'] = mse_df.rolling(20).mse.mean()\n",
    "        mse_df['smoothed_r2'] = mse_df.rolling(20).r2.mean()\n",
    "\n",
    "        melt_df = mse_df.melt(id_vars='epoch')\n",
    "        plot_df = melt_df[melt_df.variable.isin([metric, f'smoothed_{metric}'])] \n",
    "        plot_df['name'] = f\"{modelname}\" + plot_df[\"variable\"]\n",
    "        plot_data += [plot_df.copy()]\n",
    "        \n",
    "    plot_data = pd.concat(plot_data)\n",
    "    # Plot\n",
    "    fig = px.line(plot_data, x=\"epoch\", y=\"value\", color=\"name\")\n",
    "\n",
    "    if metric==\"mse\":\n",
    "        optimal_value_y = mse_df[\"mse\"].min()\n",
    "        name = \"min_mse\"\n",
    "    elif metric==\"r2\":\n",
    "        optimal_value_y = mse_df[\"r2\"].max()\n",
    "        name = \"max_r2\"\n",
    "    else:\n",
    "        raise ValueError(\"metric has to be either 'mse' or 'r2'\")\n",
    "    \n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=1200,\n",
    "        height=800,)\n",
    "\n",
    "    \n",
    "    fig.update_yaxes(range=[0.1, 1.2])\n",
    "        \n",
    "    if save:\n",
    "        main_fig.write_image(f\"{path_outputs}/{metric}_best_prediction_{modelname}.png\")\n",
    "\n",
    "    # fig.write_image(f\"{path_outputs}/mse_best_prediction_mobnet_v3_size{size}_tiles{tiles}_sample{sample}.png\")\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:12<00:00, 15.72it/s]\n"
     ]
    }
   ],
   "source": [
    "models =[\n",
    "    # \"mobnet_v3_size128_tiles1_sample1\",\n",
    "    # \"mobnet_v3_size256_tiles1_sample1\",\n",
    "    # \"mobnet_v3_size512_tiles1_sample1\",\n",
    "    \"mobnet_v3_size128_tiles1_sample5\",\n",
    "]\n",
    "\n",
    "for modelname in models:\n",
    "    mse_df = get_model_results(modelname)\n",
    "    plot_mse_over_epochs(mse_df, modelname, metric=\"mse\", save=True)\n",
    "    plot_mse_over_epochs(mse_df, modelname, metric=\"r2\", save=True)\n",
    "    plot_predictions_vs_real(mse_df, modelname=modelname, save=True)\n",
    "    plot_predictions_vs_real(mse_df, modelname=modelname, quantiles=True, save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['mobnet_v3_size128_tiles1_sample1'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/mnt/d/Maestría/Tesis/Repo/scripts/visualizar_modelos.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Maestr%C3%ADa/Tesis/Repo/scripts/visualizar_modelos.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m modelname \u001b[39m=\u001b[39m \u001b[39mrf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmobnet_v3_size128_tiles1_sample1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Maestr%C3%ADa/Tesis/Repo/scripts/visualizar_modelos.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m mse_df \u001b[39m=\u001b[39m get_model_results(modelname)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Maestr%C3%ADa/Tesis/Repo/scripts/visualizar_modelos.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m mse_df \u001b[39m=\u001b[39m get_model_results(modelname)\n",
      "\u001b[1;32m/mnt/d/Maestría/Tesis/Repo/scripts/visualizar_modelos.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Maestr%C3%ADa/Tesis/Repo/scripts/visualizar_modelos.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Get train dataset\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Maestr%C3%ADa/Tesis/Repo/scripts/visualizar_modelos.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m train_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39mrf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath_dataout\u001b[39m}\u001b[39;00m\u001b[39m/train_by_epoch.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Maestr%C3%ADa/Tesis/Repo/scripts/visualizar_modelos.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m mse_train_df \u001b[39m=\u001b[39m train_data[[modelname]]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Maestr%C3%ADa/Tesis/Repo/scripts/visualizar_modelos.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# TODO: Calcular el R2\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Maestr%C3%ADa/Tesis/Repo/scripts/visualizar_modelos.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m mse_train_df \u001b[39m=\u001b[39m mse_train_df\u001b[39m.\u001b[39mreset_index()\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m'\u001b[39m:\u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m, modelname:\u001b[39m'\u001b[39m\u001b[39mmse_train\u001b[39m\u001b[39m'\u001b[39m})\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/pandas/core/frame.py:3813\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3812\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3813\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3815\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/pandas/core/indexes/base.py:6070\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6067\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6068\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6070\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   6072\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   6073\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6074\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/pandas/core/indexes/base.py:6130\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6128\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   6129\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 6130\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6132\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[1;32m   6133\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['mobnet_v3_size128_tiles1_sample1'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "modelname = rf\"mobnet_v3_size128_tiles1_sample1\"\n",
    "mse_df = get_model_results(modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_vs_real(mse_df, modelname=modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions_vs_real(mse_df, modelname=modelname, quantiles=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridded predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "import build_dataset\n",
    "import run_model\n",
    "import tensorflow as tf\n",
    "importlib.reload(build_dataset)\n",
    "importlib.reload(run_model)\n",
    "\n",
    "# Load data\n",
    "datasets, extents = build_dataset.load_satellite_datasets()\n",
    "icpag = build_dataset.load_icpag_dataset()\n",
    "icpag = build_dataset.assign_links_to_datasets(icpag, extents)\n",
    "\n",
    "# Model\n",
    "modelpath = rf\"{folder}/mobnet_v3_size{size}_tiles{tiles}_sample{sample}_{best_case_epoch}\"\n",
    "model = tf.keras.models.load_model(\n",
    "           modelpath, compile=True\n",
    "        )\n",
    "\n",
    "# Run predictions\n",
    "grid_preds_folder = f\"{path_repo}/data/data_out/gridded_predictions/mobnet_v3_size{size}_tiles{tiles}_sample{sample}\"\n",
    "os.makedirs(grid_preds_folder, exist_ok=True)\n",
    "\n",
    "for name, ds in datasets.items():\n",
    "    df_preds = build_dataset.get_gridded_images_for_dataset(\n",
    "        model=model, ds=ds, icpag=icpag, tiles=1, size=size, resizing_size=128, bias=2, sample=1, to8bit=True\n",
    "    )\n",
    "    df_preds.to_parquet(f\"{grid_preds_folder}/{name}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = df_preds.explore(column=\"predictions\", cmap=\"Spectral\",\n",
    "                tiles=\"https://services.arcgisonline.com/arcgis/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\", attr=\"ESRI\",\n",
    "                vmax=df_preds.predictions.quantile(.95), vmin=df_preds.predictions.quantile(.05)\n",
    ")\n",
    "folium.LayerControl().add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import build_dataset\n",
    "\n",
    "build_dataset.get_random_images_for_link(\n",
    "    ds, icpag, link, 2, 512, 128, 2, 5, to8bit=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
