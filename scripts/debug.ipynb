{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import build_dataset\n",
    "\n",
    "census_data = build_dataset.load_icpag_dataset(variable=\"ln_pred_inc_mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data.to_parquet(\"census_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ofici\\AppData\\Local\\Temp\\ipykernel_12596\\1209519343.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base['run'] = base.run.str.replace(f\"/{kind}\", \"\")\n",
      "C:\\Users\\ofici\\AppData\\Local\\Temp\\ipykernel_12596\\1209519343.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base['model'] = np.nan\n",
      "C:\\Users\\ofici\\AppData\\Local\\Temp\\ipykernel_12596\\1209519343.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base['run'] = base.run.str.replace(f\"/{kind}\", \"\")\n",
      "C:\\Users\\ofici\\AppData\\Local\\Temp\\ipykernel_12596\\1209519343.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  base['model'] = np.nan\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "import numpy as np\n",
    "\n",
    "# Extract data from TB\n",
    "experiment_id = \"RAqyLXG2RMKkAXMmNEDV7Q\"\n",
    "experiment = tb.data.experimental.ExperimentFromDev(experiment_id)\n",
    "df = experiment.get_scalars()\n",
    "\n",
    "for kind in [\"train\", \"validation\"]:\n",
    "    # Keep only train values\n",
    "    base = df[df.run.str.contains(f'{kind}') & (df.tag == 'epoch_loss')]\n",
    "    base['run'] = base.run.str.replace(f\"/{kind}\", \"\")\n",
    "\n",
    "    # Filter model\n",
    "    models_by_date = { \n",
    "        'mobnet_v3_size128_tiles1_sample1':\n",
    "            [\n",
    "                'mobnet_v3_20230908-203439',\n",
    "                'mobnet_v3_20230909-020833',\n",
    "                'mobnet_v3_20230909-121048',\n",
    "                'mobnet_v3_20230909-153231',\n",
    "                'mobnet_v3_20230909-202517',\n",
    "                'mobnet_v3_20230909-213040',\n",
    "                'mobnet_v3_20230910-130103',\n",
    "                'mobnet_v3_20230911-092415',\n",
    "                'mobnet_v3_20230911-231611',\n",
    "                'mobnet_v3_20230912-012855',\n",
    "            ],\n",
    "        'mobnet_v3_size256_tiles1_sample1':\n",
    "            [       \n",
    "                'mobnet_v3_20230914-215006',\n",
    "                'mobnet_v3_20230913-200010',\n",
    "            ],      \n",
    "        'mobnet_v3_size512_tiles1_sample1':\n",
    "            [\n",
    "                'mobnet_v3_20230915-122541',\n",
    "                'mobnet_v3_20230916-124818',\n",
    "            ],\n",
    "        'mobnet_v3_size128_tiles2_sample20':\n",
    "            [\n",
    "                'mobnet_v3_20230918-192554',\n",
    "                'mobnet_v3_20230918-231134',\n",
    "                'mobnet_v3_20230919-104912',\n",
    "                'mobnet_v3_20230919-234505',\n",
    "                'mobnet_v3_20230920-131123',\n",
    "                'mobnet_v3_20230920-180458',\n",
    "                'mobnet_v3_20230920-194725',\n",
    "            ]\n",
    "    }\n",
    "\n",
    "    base['model'] = np.nan\n",
    "    for model, names in models_by_date.items():\n",
    "        for name in names:\n",
    "            base.loc[base.run.str.contains(name), 'model'] = model\n",
    "            \n",
    "    # Reshape data\n",
    "    plot_data = base[~base.model.isna()]\\\n",
    "        .drop_duplicates(subset=['model','step'], keep='first')\\\n",
    "        .pivot(index='step', columns='model', values='value')\n",
    "        \n",
    "    # Export data\n",
    "    path_repo = r\"D:/Maestría/Tesis/Repo\"\n",
    "    plot_data.to_csv(f\"{path_repo}/data/data_out/{kind}_by_epoch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'validation'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>model</th>\n",
       "      <th>mobnet_v3_size128_tiles1_sample1</th>\n",
       "      <th>mobnet_v3_size128_tiles2_sample20</th>\n",
       "      <th>mobnet_v3_size256_tiles1_sample1</th>\n",
       "      <th>mobnet_v3_size512_tiles1_sample1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>step</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.816814</td>\n",
       "      <td>0.818951</td>\n",
       "      <td>0.810019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.814255</td>\n",
       "      <td>0.824106</td>\n",
       "      <td>0.827106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.803770</td>\n",
       "      <td>0.809365</td>\n",
       "      <td>0.806643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>70.086678</td>\n",
       "      <td>0.940823</td>\n",
       "      <td>0.880816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7670.543457</td>\n",
       "      <td>0.845501</td>\n",
       "      <td>1.634859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.491770</td>\n",
       "      <td>0.419588</td>\n",
       "      <td>0.530523</td>\n",
       "      <td>0.329793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.472416</td>\n",
       "      <td>0.476143</td>\n",
       "      <td>0.332168</td>\n",
       "      <td>0.286581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.498945</td>\n",
       "      <td>0.495958</td>\n",
       "      <td>0.600452</td>\n",
       "      <td>0.429535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.534262</td>\n",
       "      <td>0.505298</td>\n",
       "      <td>0.559504</td>\n",
       "      <td>0.395025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.514170</td>\n",
       "      <td>0.655900</td>\n",
       "      <td>0.573847</td>\n",
       "      <td>0.346885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "model  mobnet_v3_size128_tiles1_sample1  mobnet_v3_size128_tiles2_sample20  \\\n",
       "step                                                                         \n",
       "0                                   NaN                           0.816814   \n",
       "1                                   NaN                           0.814255   \n",
       "2                                   NaN                           0.803770   \n",
       "3                                   NaN                          70.086678   \n",
       "4                                   NaN                        7670.543457   \n",
       "...                                 ...                                ...   \n",
       "195                            0.491770                           0.419588   \n",
       "196                            0.472416                           0.476143   \n",
       "197                            0.498945                           0.495958   \n",
       "198                            0.534262                           0.505298   \n",
       "199                            0.514170                           0.655900   \n",
       "\n",
       "model  mobnet_v3_size256_tiles1_sample1  mobnet_v3_size512_tiles1_sample1  \n",
       "step                                                                       \n",
       "0                              0.818951                          0.810019  \n",
       "1                              0.824106                          0.827106  \n",
       "2                              0.809365                          0.806643  \n",
       "3                              0.940823                          0.880816  \n",
       "4                              0.845501                          1.634859  \n",
       "...                                 ...                               ...  \n",
       "195                            0.530523                          0.329793  \n",
       "196                            0.332168                          0.286581  \n",
       "197                            0.600452                          0.429535  \n",
       "198                            0.559504                          0.395025  \n",
       "199                            0.573847                          0.346885  \n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>tag</th>\n",
       "      <th>step</th>\n",
       "      <th>value</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>mobnet_v3_size128_tiles1_sample1/mobnet_v3_202...</td>\n",
       "      <td>epoch_loss</td>\n",
       "      <td>14</td>\n",
       "      <td>0.837110</td>\n",
       "      <td>mobnet_v3_size128_tiles1_sample1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>mobnet_v3_size128_tiles1_sample1/mobnet_v3_202...</td>\n",
       "      <td>epoch_loss</td>\n",
       "      <td>15</td>\n",
       "      <td>1.043880</td>\n",
       "      <td>mobnet_v3_size128_tiles1_sample1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>mobnet_v3_size128_tiles1_sample1/mobnet_v3_202...</td>\n",
       "      <td>epoch_loss</td>\n",
       "      <td>16</td>\n",
       "      <td>0.758083</td>\n",
       "      <td>mobnet_v3_size128_tiles1_sample1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>mobnet_v3_size128_tiles1_sample1/mobnet_v3_202...</td>\n",
       "      <td>epoch_loss</td>\n",
       "      <td>17</td>\n",
       "      <td>0.628917</td>\n",
       "      <td>mobnet_v3_size128_tiles1_sample1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>mobnet_v3_size128_tiles1_sample1/mobnet_v3_202...</td>\n",
       "      <td>epoch_loss</td>\n",
       "      <td>18</td>\n",
       "      <td>0.634569</td>\n",
       "      <td>mobnet_v3_size128_tiles1_sample1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7295</th>\n",
       "      <td>mobnet_v3_size512_tiles1_sample1/mobnet_v3_202...</td>\n",
       "      <td>epoch_loss</td>\n",
       "      <td>195</td>\n",
       "      <td>0.329793</td>\n",
       "      <td>mobnet_v3_size512_tiles1_sample1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7296</th>\n",
       "      <td>mobnet_v3_size512_tiles1_sample1/mobnet_v3_202...</td>\n",
       "      <td>epoch_loss</td>\n",
       "      <td>196</td>\n",
       "      <td>0.286581</td>\n",
       "      <td>mobnet_v3_size512_tiles1_sample1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7297</th>\n",
       "      <td>mobnet_v3_size512_tiles1_sample1/mobnet_v3_202...</td>\n",
       "      <td>epoch_loss</td>\n",
       "      <td>197</td>\n",
       "      <td>0.429535</td>\n",
       "      <td>mobnet_v3_size512_tiles1_sample1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7298</th>\n",
       "      <td>mobnet_v3_size512_tiles1_sample1/mobnet_v3_202...</td>\n",
       "      <td>epoch_loss</td>\n",
       "      <td>198</td>\n",
       "      <td>0.395025</td>\n",
       "      <td>mobnet_v3_size512_tiles1_sample1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7299</th>\n",
       "      <td>mobnet_v3_size512_tiles1_sample1/mobnet_v3_202...</td>\n",
       "      <td>epoch_loss</td>\n",
       "      <td>199</td>\n",
       "      <td>0.346885</td>\n",
       "      <td>mobnet_v3_size512_tiles1_sample1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>789 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    run         tag  step  \\\n",
       "64    mobnet_v3_size128_tiles1_sample1/mobnet_v3_202...  epoch_loss    14   \n",
       "65    mobnet_v3_size128_tiles1_sample1/mobnet_v3_202...  epoch_loss    15   \n",
       "66    mobnet_v3_size128_tiles1_sample1/mobnet_v3_202...  epoch_loss    16   \n",
       "67    mobnet_v3_size128_tiles1_sample1/mobnet_v3_202...  epoch_loss    17   \n",
       "68    mobnet_v3_size128_tiles1_sample1/mobnet_v3_202...  epoch_loss    18   \n",
       "...                                                 ...         ...   ...   \n",
       "7295  mobnet_v3_size512_tiles1_sample1/mobnet_v3_202...  epoch_loss   195   \n",
       "7296  mobnet_v3_size512_tiles1_sample1/mobnet_v3_202...  epoch_loss   196   \n",
       "7297  mobnet_v3_size512_tiles1_sample1/mobnet_v3_202...  epoch_loss   197   \n",
       "7298  mobnet_v3_size512_tiles1_sample1/mobnet_v3_202...  epoch_loss   198   \n",
       "7299  mobnet_v3_size512_tiles1_sample1/mobnet_v3_202...  epoch_loss   199   \n",
       "\n",
       "         value                             model  \n",
       "64    0.837110  mobnet_v3_size128_tiles1_sample1  \n",
       "65    1.043880  mobnet_v3_size128_tiles1_sample1  \n",
       "66    0.758083  mobnet_v3_size128_tiles1_sample1  \n",
       "67    0.628917  mobnet_v3_size128_tiles1_sample1  \n",
       "68    0.634569  mobnet_v3_size128_tiles1_sample1  \n",
       "...        ...                               ...  \n",
       "7295  0.329793  mobnet_v3_size512_tiles1_sample1  \n",
       "7296  0.286581  mobnet_v3_size512_tiles1_sample1  \n",
       "7297  0.429535  mobnet_v3_size512_tiles1_sample1  \n",
       "7298  0.395025  mobnet_v3_size512_tiles1_sample1  \n",
       "7299  0.346885  mobnet_v3_size512_tiles1_sample1  \n",
       "\n",
       "[789 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Maestría\\Tesis\\Repo\\scripts\\debug.ipynb Cell 1\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Maestr%C3%ADa/Tesis/Repo/scripts/debug.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mimportlib\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Maestr%C3%ADa/Tesis/Repo/scripts/debug.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Maestr%C3%ADa/Tesis/Repo/scripts/debug.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Maestr%C3%ADa/Tesis/Repo/scripts/debug.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mutils\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ofici\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\__init__.py:22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[0;32m     21\u001b[0m \u001b[39m# numpy compat\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m \u001b[39mimport\u001b[39;00m is_numpy_dev \u001b[39mas\u001b[39;00m _is_numpy_dev  \u001b[39m# pyright: ignore # noqa:F401\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_libs\u001b[39;00m \u001b[39mimport\u001b[39;00m hashtable \u001b[39mas\u001b[39;00m _hashtable, lib \u001b[39mas\u001b[39;00m _lib, tslib \u001b[39mas\u001b[39;00m _tslib\n",
      "File \u001b[1;32mc:\\Users\\ofici\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\compat\\__init__.py:29\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompressors\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnumpy\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     26\u001b[0m     is_numpy_dev,\n\u001b[0;32m     27\u001b[0m     np_version_under1p21,\n\u001b[0;32m     28\u001b[0m )\n\u001b[1;32m---> 29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyarrow\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     30\u001b[0m     pa_version_under7p0,\n\u001b[0;32m     31\u001b[0m     pa_version_under8p0,\n\u001b[0;32m     32\u001b[0m     pa_version_under9p0,\n\u001b[0;32m     33\u001b[0m     pa_version_under11p0,\n\u001b[0;32m     34\u001b[0m )\n\u001b[0;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_function_name\u001b[39m(f: F, name: \u001b[39mstr\u001b[39m, \u001b[39mcls\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m F:\n\u001b[0;32m     38\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[39m    Bind the name/qualname attributes of the function.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ofici\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\compat\\pyarrow.py:8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversion\u001b[39;00m \u001b[39mimport\u001b[39;00m Version\n\u001b[0;32m      7\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m----> 8\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mpyarrow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpa\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     _pa_version \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39m__version__\n\u001b[0;32m     11\u001b[0m     _palv \u001b[39m=\u001b[39m Version(_pa_version)\n",
      "File \u001b[1;32mc:\\Users\\ofici\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyarrow\\__init__.py:65\u001b[0m\n\u001b[0;32m     63\u001b[0m _gc_enabled \u001b[39m=\u001b[39m _gc\u001b[39m.\u001b[39misenabled()\n\u001b[0;32m     64\u001b[0m _gc\u001b[39m.\u001b[39mdisable()\n\u001b[1;32m---> 65\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpyarrow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlib\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_lib\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[39mif\u001b[39;00m _gc_enabled:\n\u001b[0;32m     67\u001b[0m     _gc\u001b[39m.\u001b[39menable()\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:405\u001b[0m, in \u001b[0;36mparent\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import utils\n",
    "import build_dataset as bd\n",
    "import run_model\n",
    "\n",
    "importlib.reload(run_model)\n",
    "importlib.reload(utils)\n",
    "\n",
    "path_repo = r\"/mnt/d/Maestría/Tesis/Repo/\"\n",
    "\n",
    "log_dir = f\"{path_repo}/logs/mobnet_v3_20230905-231447\"\n",
    "models_dir = f\"{path_repo}/data/data_out/models_by_epoch\"\n",
    "model_name = \"mobnet_v3\"\n",
    "metadata = pd.read_csv(f\"{path_repo}/data/data_out/size128_sample10/metadata.csv\")\n",
    "tiles = 1\n",
    "size = 128\n",
    "resizing_size = 128\n",
    "bias = 2\n",
    "sample = 1\n",
    "to8bit = True\n",
    "n_epochs = 20\n",
    "\n",
    "\n",
    "# modelpath = rf\"{path_repo}/data/data_out/models_by_epoch/mobnet_v3_25\"\n",
    "# model = tf.keras.models.load_model(\n",
    "#            modelpath, compile=True\n",
    "#         )\n",
    "# metadata = metadata.loc[metadata.type == \"test\", \"link\"]\n",
    "# df_prediciones, mse = run_model.compute_custom_loss(\n",
    "#     model, metadata, tiles, size, resizing_size, bias, sample, to8bit\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import os\n",
    "path_pansharpened = r\"D:\\Maestría\\Tesis\\Repo\\data\\data_in\\Pansharpened\\2013\"\n",
    "files = os.listdir(path_pansharpened)\n",
    "tifs = [f for f in files if f.endswith(\".tif\")]\n",
    "tifs\n",
    "\n",
    "ds1 = xr.open_dataset(rf\"{path_pansharpened}\\{tifs[0]}\")\n",
    "ds2 = xr.open_dataset(rf\"{path_pansharpened}\\{tifs[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr.combine_by_coords([ds1, ds2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "064100610: 0/1\n",
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "df_prediciones, mse = run_model.compute_custom_loss(\n",
    "    model, metadata[metadata.link == int(64100610)], tiles, size, resizing_size, bias, sample, to8bit\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import build_dataset\n",
    "import run_model\n",
    "import utils\n",
    "import matplotlib\n",
    "import geopandas as gpd\n",
    "from shapely import Polygon\n",
    "importlib.reload(build_dataset)\n",
    "importlib.reload(utils)\n",
    "\n",
    "link = '064100610'\n",
    "\n",
    "# Load datasets\n",
    "datasets, extents = build_dataset.load_satellite_datasets()\n",
    "icpag = build_dataset.load_icpag_dataset()\n",
    "icpag = build_dataset.assign_links_to_datasets(icpag, extents, verbose=False)\n",
    "\n",
    "# Get the dataset with the images of the selected link\n",
    "ds = build_dataset.get_dataset_for_link(icpag, datasets, link)\n",
    "\n",
    "# Get the grid of the images\n",
    "images, points, bounds = build_dataset.get_gridded_images_for_link(\n",
    "    ds, icpag, link, tiles=1, size=128, resizing_size=128, bias=4, sample=1, to8bit=True\n",
    ")\n",
    "\n",
    "# Compute loss\n",
    "df_prediciones, mse = run_model.compute_custom_loss(\n",
    "    model, metadata[metadata.link == int(link)], tiles, size, resizing_size, bias, sample, to8bit\n",
    ")\n",
    "\n",
    "# Make geodataframe with the images and its predictions\n",
    "polygons = [Polygon(bound[0]) for bound in bounds]\n",
    "predictions = df_prediciones[df_prediciones['link']==link].predictions.values[0]\n",
    "predictions_gdf =  gpd.GeoDataFrame(predictions, geometry=polygons).rename(columns={0:'predictions'}).set_crs(epsg=4326)\n",
    "\n",
    "#### Plot\n",
    "import folium\n",
    "# Plot census tract\n",
    "m = icpag[icpag.link == link].explore(\n",
    "        tiles=\"https://services.arcgisonline.com/arcgis/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\", attr=\"ESRI\",\n",
    "        \n",
    ")\n",
    "# Plot gridded predictions\n",
    "predictions_gdf.explore(column='predictions', cmap='Spectral', vmin=-1, vmax=1, m=m)\n",
    "\n",
    "# Add control for switching between layers\n",
    "folium.LayerControl().add_to(m)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42271230232120466"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import run_model\n",
    "import pandas as pd\n",
    "import importlib\n",
    "importlib.reload(run_model)\n",
    "\n",
    "path_repo = r\"/mnt/d/Maestría/Tesis/Repo/\"\n",
    "modelpath = rf\"{path_repo}/data/data_out/models_by_epoch/mobnet_v3_25\"\n",
    "# model = tf.keras.models.load_model(\n",
    "#            modelpath, compile=True\n",
    "#         )\n",
    "# metadata = pd.read_csv(f\"{path_repo}/data/data_out/train_size128_tiles1_sample10/metadata.csv\")\n",
    "tiles, size, resizing_size, bias, sample = 1, 128, 128, 2, 1\n",
    "\n",
    "df, mse = run_model.compute_custom_loss(\n",
    "    model, metadata, tiles, size, resizing_size, bias, sample, True, verbose=True\n",
    ")a\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metadata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/d/Maestría/Tesis/Repo/scripts/debug.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Maestr%C3%ADa/Tesis/Repo/scripts/debug.ipynb#X64sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m metadata\u001b[39m.\u001b[39mloc[metadata\u001b[39m.\u001b[39mlink \u001b[39m==\u001b[39m\u001b[39m10\u001b[39m ]\u001b[39m.\u001b[39micpag\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metadata' is not defined"
     ]
    }
   ],
   "source": [
    "metadata.loc[metadata.link ==10 ].icpag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_gdf.explore(column='predictions', cmap='Spectral', vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.concatenate([np.array([10,20,30]),np.array([10])]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorize(prediction, vmin=vmin, vmax=vmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "metadata = pd.read_csv(r\"D:\\Maestría\\Tesis\\Repo\\data\\data_out\\size512_sample5\\metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 20010101\n",
    "metadata.loc[metadata.link == link, 'var'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(\"./data/icpag.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "path_dataout = r\"D:\\Maestría\\Tesis\\Repo\\data\\data_out\"\n",
    "model_path=fr\"{path_dataout}/models/mobnet_v3_20230831-172738\"\n",
    "\n",
    "keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage\n",
    "img = np.load(r\"D:\\Maestría\\Tesis\\Repo\\data\\data_out\\size128_sample10\\020010103_1.npy\")\n",
    "img = np.moveaxis(img, 0, 2)[:,:,:3]\n",
    "# equalize hist\n",
    "img = skimage.exposure.equalize_hist(img)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import earthpy.plot as ep\n",
    "\n",
    "# ep.plot_rgb(images[0], rgb=[0, 1, 2], title=\"RGB Image\", stretch=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dotenv import dotenv_values\n",
    "image_size = 200\n",
    "sample_size = 1\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "env = dotenv_values(\"D:/Maestría/Tesis/Repo/scripts/globals.env\")\n",
    "\n",
    "path_proyecto = env[\"PATH_PROYECTO\"]\n",
    "path_datain = env[\"PATH_DATAIN\"]\n",
    "path_dataout = env[\"PATH_DATAOUT\"]\n",
    "path_scripts = env[\"PATH_SCRIPTS\"]\n",
    "path_satelites = env[\"PATH_SATELITES\"]\n",
    "path_logs = env[\"PATH_LOGS\"]\n",
    "path_outputs = env[\"PATH_OUTPUTS\"]\n",
    "\n",
    "# df = pd.read_csv(\n",
    "#     rf\"D:\\Maestría\\Tesis\\Repo\\data\\data_out\\size500_sample1\\metadata.csv\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import build_dataset\n",
    "importlib.reload(build_dataset)\n",
    "variable = \"ln_pred_inc_mean\"\n",
    "datasets, extents = build_dataset.load_satellite_datasets()\n",
    "icpag = build_dataset.load_icpag_dataset(variable)\n",
    "icpag = build_dataset.assign_links_to_datasets(icpag, extents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import run_model\n",
    "import importlib\n",
    "importlib.reload(run_model)\n",
    "\n",
    "kind=\"reg\"\n",
    "image_size = 500\n",
    "resizing_size = 200\n",
    "my_test = \"ddddddd\"\n",
    "train_dataset, test_dataset, filenames = run_model.create_and_build_datasets(\n",
    "    kind=kind,\n",
    "    image_size=image_size,\n",
    "    resizing_size=resizing_size,\n",
    "    batch_size=32,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icpag['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "imgs = np.load(r\"D:\\Maestría\\Tesis\\Repo\\outputs\\examples_0_img.npy\")\n",
    "labs = np.load(r\"D:\\Maestría\\Tesis\\Repo\\outputs\\examples_0_lab.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(file_path, label):\n",
    "    import cv2\n",
    "    \n",
    "    img = np.load(file_path)\n",
    "    img = np.moveaxis(\n",
    "        img, 0, 2\n",
    "    )  # Move axis so the original [4, 512, 512] becames [512, 512, 4]\n",
    "    img = cv2.resize(\n",
    "        img, dsize=(resizing_size, resizing_size), interpolation=cv2.INTER_CUBIC\n",
    "    )\n",
    "\n",
    "    img = tf.convert_to_tensor(img / 255, dtype=tf.float32)\n",
    "    label = tf.cast(label, tf.float32)\n",
    "\n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "resizing_size = 200\n",
    "img, label = process_image(r\"D:\\Maestría\\Tesis\\Repo\\data\\data_out\\size500_sample1\\062742004_0.npy\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "example = tfds.as_numpy(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(example[:,:,0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = r\"D:\\Maestría\\Tesis\\Repo\\data\\data_out\\size500_sample1\"\n",
    "files = [f\"{path}\\{file}\" for file in os.listdir(path)]\n",
    "\n",
    "labels = [0] * len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((files, labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(\n",
    "    lambda file, label: tf.numpy_function(\n",
    "        process_image, [file, label], (tf.float32, tf.float32)\n",
    "    )\n",
    ")  # Parse every image in the dataset using `map`\n",
    "\n",
    "imgs = []\n",
    "labs = []\n",
    "for x in dataset.take(1):\n",
    "    imgs += [tfds.as_numpy(x)[0]]\n",
    "    labs += [tfds.as_numpy(x)[1]]\n",
    "    \n",
    "imgs\n",
    "#### HASTA ACA TODO GENIAL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "        [\n",
    "            layers.RandomFlip(\n",
    "                \"horizontal_and_vertical\",\n",
    "                seed=825,\n",
    "                input_shape=(resizing_size, resizing_size, 4),\n",
    "            ),\n",
    "            # layers.RandomTranslation(0.3, 0.3, fill_mode=\"reflect\", seed=825),\n",
    "            # layers.RandomHeight(0.3),\n",
    "            # layers.RandomWidth(0.3),\n",
    "            # layers.RandomZoom(0.3, seed=825),\n",
    "            # layers.RandomContrast(0.3, seed=825),\n",
    "            # layers.RandomBrightness(0.05, value_range=(0,1), seed=825),\n",
    "            # layers.RandomCrop(image_size, image_size, seed=825),\n",
    "        ],\n",
    "        name=\"data_augmentation\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (\n",
    "    dataset.shuffle(round(len(files[0]) / 10))\n",
    "    .batch(32)\n",
    "    .map(lambda x, y: (data_augmentation(x), y))\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "ds = datasets[icpag.loc[icpag.link == \"065150214\", \"dataset\"].values[0]]\n",
    "composition, point, boundaries, total_boundaries = utils.random_image_from_census_tract(\n",
    "    ds, icpag, \"065150214\", tiles=2, size=500, bias=4, to8bit=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "labs = []\n",
    "for x in train_dataset.take(1):\n",
    "    imgs += [tfds.as_numpy(x)[0]]\n",
    "    labs += [tfds.as_numpy(x)[1]]\n",
    "\n",
    "print(imgs[0][0].shape)    \n",
    "plt.imshow(imgs[0][0][:,:,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 1\n",
    "image_size = 500\n",
    "path_dataout = r\"D:/Maestría/Tesis/Repo/data/data_out\"\n",
    "\n",
    "df = pd.read_csv(\n",
    "    rf\"{path_dataout}/size{image_size}_sample{sample_size}/metadata.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_column_to_x_y(df):\n",
    "    df.point = df.point.str.replace(\"\\(|\\)\", \"\", regex=True).str.split(\",\")\n",
    "    df['x'] = df.point.str[0]\n",
    "    df['y']= df.point.str[1]\n",
    "    return df[['x', 'y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "df = df.dropna(how=\"any\").reset_index(drop=True)\n",
    "df[['x', 'y']] = point_column_to_x_y(df)\n",
    "df.x, df.y = df.x.astype(float), df.y.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import build_dataset\n",
    "import pandas as pd\n",
    "path_dataout = r\"D:/Maestría/Tesis/Repo/data/data_out\"\n",
    "\n",
    "# build_dataset.build_dataset(200, 1, variable=\"ln_pred_inc_mean\")\n",
    "df = pd.read_csv(\n",
    "    rf\"{path_dataout}/size200_sample1/metadata.csv\"\n",
    ")\n",
    "\n",
    "metadata = build_dataset.split_train_test(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import build_dataset\n",
    "import utils\n",
    "importlib.reload(build_dataset)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(build_dataset)\n",
    "build_dataset.build_dataset(500, 1, tiles=2, bias=4, variable=\"ln_pred_inc_mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(build_dataset)\n",
    "df = pd.read_csv(\n",
    "    rf\"{path_dataout}/size500_sample1/metadata.csv\"\n",
    ")\n",
    "# df = df.drop(columns=\"Test\")\n",
    "# df = build_dataset.split_train_test(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
