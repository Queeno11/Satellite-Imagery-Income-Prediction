{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dotenv import dotenv_values\n",
    "image_size = 200\n",
    "sample_size = 1\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "env = dotenv_values(\"D:/Maestría/Tesis/Repo/scripts/globals.env\")\n",
    "\n",
    "path_proyecto = env[\"PATH_PROYECTO\"]\n",
    "path_datain = env[\"PATH_DATAIN\"]\n",
    "path_dataout = env[\"PATH_DATAOUT\"]\n",
    "path_scripts = env[\"PATH_SCRIPTS\"]\n",
    "path_satelites = env[\"PATH_SATELITES\"]\n",
    "path_logs = env[\"PATH_LOGS\"]\n",
    "path_outputs = env[\"PATH_OUTPUTS\"]\n",
    "\n",
    "df = pd.read_csv(\n",
    "    rf\"D:\\Maestría\\Tesis\\Repo\\data\\data_out\\size500_sample1\\metadata.csv\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"D:\\Maestría\\Tesis\\Repo\\data\\data_out\\size500_sample1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 811/11666 [00:29<06:35, 27.46it/s]  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Object arrays cannot be loaded when allow_pickle=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m tqdm(df\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mvalues):\n\u001b[0;32m      5\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mrf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mD:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mMaestría\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mTesis\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mRepo\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mdata_out\u001b[39m\u001b[39m\\\u001b[39m\u001b[39msize500_sample1\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m{\u001b[39;00mimg\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m    \n\u001b[1;32m----> 6\u001b[0m     \u001b[39massert\u001b[39;00m np\u001b[39m.\u001b[39;49mload(img)\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m (\u001b[39m4\u001b[39m, \u001b[39m500\u001b[39m, \u001b[39m500\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ofici\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\npyio.py:432\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39m\u001b[39m.\u001b[39mopen_memmap(file, mode\u001b[39m=\u001b[39mmmap_mode,\n\u001b[0;32m    430\u001b[0m                                   max_header_size\u001b[39m=\u001b[39mmax_header_size)\n\u001b[0;32m    431\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 432\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mformat\u001b[39;49m\u001b[39m.\u001b[39;49mread_array(fid, allow_pickle\u001b[39m=\u001b[39;49mallow_pickle,\n\u001b[0;32m    433\u001b[0m                                  pickle_kwargs\u001b[39m=\u001b[39;49mpickle_kwargs,\n\u001b[0;32m    434\u001b[0m                                  max_header_size\u001b[39m=\u001b[39;49mmax_header_size)\n\u001b[0;32m    435\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    436\u001b[0m     \u001b[39m# Try a pickle\u001b[39;00m\n\u001b[0;32m    437\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[1;32mc:\\Users\\ofici\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\format.py:787\u001b[0m, in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[39mif\u001b[39;00m dtype\u001b[39m.\u001b[39mhasobject:\n\u001b[0;32m    785\u001b[0m     \u001b[39m# The array contained Python objects. We need to unpickle the data.\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_pickle:\n\u001b[1;32m--> 787\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mObject arrays cannot be loaded when \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    788\u001b[0m                          \u001b[39m\"\u001b[39m\u001b[39mallow_pickle=False\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    789\u001b[0m     \u001b[39mif\u001b[39;00m pickle_kwargs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    790\u001b[0m         pickle_kwargs \u001b[39m=\u001b[39m {}\n",
      "\u001b[1;31mValueError\u001b[0m: Object arrays cannot be loaded when allow_pickle=False"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "for img in tqdm(df.image.values):\n",
    "    img = rf'D:\\Maestría\\Tesis\\Repo\\data\\data_out\\size500_sample1\\{img.split(\"/\")[-1]}'    \n",
    "    assert np.load(img).shape == (4, 500, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(None, dtype=object)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.load(r\"D:\\Maestría\\Tesis\\Repo\\data\\data_out\\size500_sample1\\020040308_0.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "filenames = tf.constant(df[\"image\"].to_list())\n",
    "labels = tf.constant(df[\"var\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/d/Maestría/Tesis/Repo/data/data_out/size500_sample1/020010101_0.npy'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.image[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/d/Maestría/Tesis/Repo/data/data_out/size500_sample1/020010101_0.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m np\u001b[39m.\u001b[39;49mload(df\u001b[39m.\u001b[39;49mimage[\u001b[39m0\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\Users\\ofici\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    403\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 405\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m    406\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    408\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/d/Maestría/Tesis/Repo/data/data_out/size500_sample1/020010101_0.npy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.load(df.image[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "env = dotenv_values(\"/mnt/d/Maestría/Tesis/Repo/scripts/globals.env\")\n",
    "\n",
    "path_proyecto = env[\"PATH_PROYECTO\"]\n",
    "path_datain = env[\"PATH_DATAIN\"]\n",
    "path_dataout = env[\"PATH_DATAOUT\"]\n",
    "path_scripts = env[\"PATH_SCRIPTS\"]\n",
    "path_satelites = env[\"PATH_SATELITES\"]\n",
    "path_logs = env[\"PATH_LOGS\"]\n",
    "path_outputs = env[\"PATH_OUTPUTS\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 512\n",
    "sample_size=10\n",
    "kind=\"reg\"\n",
    "weights = \"imagenet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 15:14:36.777718: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-02 15:14:36.777859: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-02 15:14:36.777911: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-02 15:14:38.164782: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-02 15:14:38.164893: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-02 15:14:38.164904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-08-02 15:14:38.164959: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-08-02 15:14:38.164990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5903 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "get_model_from_name = {\n",
    "    # \"small_cnn\": custom_models.small_cnn(),  # kind=kind),\n",
    "    \"mobnet_v3\": custom_models.mobnet_v3(kind=kind, weights=weights),\n",
    "    # \"resnet152_v2\": custom_models.resnet152_v2(kind=kind, weights=weights),\n",
    "    \"effnet_v2_b0\": custom_models.effnet_v2_b0(kind=kind, weights=weights),\n",
    "    \"effnet_v2_s\": custom_models.effnet_v2_s(kind=kind, weights=weights),\n",
    "    \"effnet_v2_l\": custom_models.effnet_v2_l(kind=kind, weights=weights),\n",
    "    # \"effnet_b0\": custom_models.effnet_b0(kind=kind, weights=weights),\n",
    "}\n",
    "\n",
    "# Open dataframe with files and labels\n",
    "df = pd.read_csv(\n",
    "    rf\"{path_dataout}/size{image_size}_sample{sample_size}/metadata.csv\"\n",
    ")\n",
    "\n",
    "# Set loss and metrics\n",
    "loss = keras.losses.MeanSquaredError()\n",
    "metrics = [keras.metrics.MeanAbsoluteError(), keras.metrics.MeanSquaredError()]\n",
    "\n",
    "\n",
    "# Clean dataframe and create datasets\n",
    "df = df.dropna(subset=[\"var\"] + [\"image\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>point</th>\n",
       "      <th>sample</th>\n",
       "      <th>link</th>\n",
       "      <th>image</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>020010101_0</td>\n",
       "      <td>(-58.36156751878867, -34.58216718996734)</td>\n",
       "      <td>0</td>\n",
       "      <td>20010101</td>\n",
       "      <td>/mnt/d/Maestría/Tesis/Repo/data/data_out/size5...</td>\n",
       "      <td>818.70233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>020010101_1</td>\n",
       "      <td>(-58.37118880713666, -34.5811089755725)</td>\n",
       "      <td>1</td>\n",
       "      <td>20010101</td>\n",
       "      <td>/mnt/d/Maestría/Tesis/Repo/data/data_out/size5...</td>\n",
       "      <td>818.70233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>020010101_2</td>\n",
       "      <td>(-58.36632936754825, -34.58471387955013)</td>\n",
       "      <td>2</td>\n",
       "      <td>20010101</td>\n",
       "      <td>/mnt/d/Maestría/Tesis/Repo/data/data_out/size5...</td>\n",
       "      <td>818.70233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>020010101_3</td>\n",
       "      <td>(-58.36974813399578, -34.580278584375634)</td>\n",
       "      <td>3</td>\n",
       "      <td>20010101</td>\n",
       "      <td>/mnt/d/Maestría/Tesis/Repo/data/data_out/size5...</td>\n",
       "      <td>818.70233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>020010101_4</td>\n",
       "      <td>(-58.370946671444294, -34.58178858107447)</td>\n",
       "      <td>4</td>\n",
       "      <td>20010101</td>\n",
       "      <td>/mnt/d/Maestría/Tesis/Repo/data/data_out/size5...</td>\n",
       "      <td>818.70233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115682</th>\n",
       "      <td>068613310_5</td>\n",
       "      <td>(-58.54953342915249, -34.53134027392235)</td>\n",
       "      <td>5</td>\n",
       "      <td>68613310</td>\n",
       "      <td>/mnt/d/Maestría/Tesis/Repo/data/data_out/size5...</td>\n",
       "      <td>922.37670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115683</th>\n",
       "      <td>068613310_6</td>\n",
       "      <td>(-58.55006329312647, -34.53141510569217)</td>\n",
       "      <td>6</td>\n",
       "      <td>68613310</td>\n",
       "      <td>/mnt/d/Maestría/Tesis/Repo/data/data_out/size5...</td>\n",
       "      <td>922.37670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115684</th>\n",
       "      <td>068613310_7</td>\n",
       "      <td>(-58.55100445910311, -34.530066091808145)</td>\n",
       "      <td>7</td>\n",
       "      <td>68613310</td>\n",
       "      <td>/mnt/d/Maestría/Tesis/Repo/data/data_out/size5...</td>\n",
       "      <td>922.37670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115685</th>\n",
       "      <td>068613310_8</td>\n",
       "      <td>(-58.55208362894792, -34.5308488344588)</td>\n",
       "      <td>8</td>\n",
       "      <td>68613310</td>\n",
       "      <td>/mnt/d/Maestría/Tesis/Repo/data/data_out/size5...</td>\n",
       "      <td>922.37670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115686</th>\n",
       "      <td>068613310_9</td>\n",
       "      <td>(-58.551231033043955, -34.532312638172726)</td>\n",
       "      <td>9</td>\n",
       "      <td>68613310</td>\n",
       "      <td>/mnt/d/Maestría/Tesis/Repo/data/data_out/size5...</td>\n",
       "      <td>922.37670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115687 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0                                       point  sample  \\\n",
       "0       020010101_0    (-58.36156751878867, -34.58216718996734)       0   \n",
       "1       020010101_1     (-58.37118880713666, -34.5811089755725)       1   \n",
       "2       020010101_2    (-58.36632936754825, -34.58471387955013)       2   \n",
       "3       020010101_3   (-58.36974813399578, -34.580278584375634)       3   \n",
       "4       020010101_4   (-58.370946671444294, -34.58178858107447)       4   \n",
       "...             ...                                         ...     ...   \n",
       "115682  068613310_5    (-58.54953342915249, -34.53134027392235)       5   \n",
       "115683  068613310_6    (-58.55006329312647, -34.53141510569217)       6   \n",
       "115684  068613310_7   (-58.55100445910311, -34.530066091808145)       7   \n",
       "115685  068613310_8     (-58.55208362894792, -34.5308488344588)       8   \n",
       "115686  068613310_9  (-58.551231033043955, -34.532312638172726)       9   \n",
       "\n",
       "            link                                              image        var  \n",
       "0       20010101  /mnt/d/Maestría/Tesis/Repo/data/data_out/size5...  818.70233  \n",
       "1       20010101  /mnt/d/Maestría/Tesis/Repo/data/data_out/size5...  818.70233  \n",
       "2       20010101  /mnt/d/Maestría/Tesis/Repo/data/data_out/size5...  818.70233  \n",
       "3       20010101  /mnt/d/Maestría/Tesis/Repo/data/data_out/size5...  818.70233  \n",
       "4       20010101  /mnt/d/Maestría/Tesis/Repo/data/data_out/size5...  818.70233  \n",
       "...          ...                                                ...        ...  \n",
       "115682  68613310  /mnt/d/Maestría/Tesis/Repo/data/data_out/size5...  922.37670  \n",
       "115683  68613310  /mnt/d/Maestría/Tesis/Repo/data/data_out/size5...  922.37670  \n",
       "115684  68613310  /mnt/d/Maestría/Tesis/Repo/data/data_out/size5...  922.37670  \n",
       "115685  68613310  /mnt/d/Maestría/Tesis/Repo/data/data_out/size5...  922.37670  \n",
       "115686  68613310  /mnt/d/Maestría/Tesis/Repo/data/data_out/size5...  922.37670  \n",
       "\n",
       "[115687 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>point</th>\n",
       "      <th>sample</th>\n",
       "      <th>link</th>\n",
       "      <th>image</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25521</th>\n",
       "      <td>020121101_8</td>\n",
       "      <td>(-58.47859271375325, -34.571505645575606)</td>\n",
       "      <td>8</td>\n",
       "      <td>20121101</td>\n",
       "      <td>/mnt/d/Maestría/Tesis/Repo/data/data_out/size5...</td>\n",
       "      <td>1331.56750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39824</th>\n",
       "      <td>060283915_2</td>\n",
       "      <td>(-58.36645586727871, -34.890629245300666)</td>\n",
       "      <td>2</td>\n",
       "      <td>60283915</td>\n",
       "      <td>/mnt/d/Maestría/Tesis/Repo/data/data_out/size5...</td>\n",
       "      <td>440.83040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64391</th>\n",
       "      <td>064274406_2</td>\n",
       "      <td>(-58.570124123271434, -34.678458147020805)</td>\n",
       "      <td>2</td>\n",
       "      <td>64274406</td>\n",
       "      <td>/mnt/d/Maestría/Tesis/Repo/data/data_out/size5...</td>\n",
       "      <td>679.80255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19248</th>\n",
       "      <td>020090612_7</td>\n",
       "      <td>(-58.49770402766182, -34.6505026763707)</td>\n",
       "      <td>7</td>\n",
       "      <td>20090612</td>\n",
       "      <td>/mnt/d/Maestría/Tesis/Repo/data/data_out/size5...</td>\n",
       "      <td>1037.93380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17925</th>\n",
       "      <td>020080907_6</td>\n",
       "      <td>(-58.47890874375637, -34.69102782934132)</td>\n",
       "      <td>6</td>\n",
       "      <td>20080907</td>\n",
       "      <td>/mnt/d/Maestría/Tesis/Repo/data/data_out/size5...</td>\n",
       "      <td>1048.67290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51318</th>\n",
       "      <td>063711609_5</td>\n",
       "      <td>(-58.58515157423012, -34.540520500982936)</td>\n",
       "      <td>5</td>\n",
       "      <td>63711609</td>\n",
       "      <td>/mnt/d/Maestría/Tesis/Repo/data/data_out/size5...</td>\n",
       "      <td>573.58120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12320</th>\n",
       "      <td>020052206_4</td>\n",
       "      <td>(-58.42173486312725, -34.63288663366313)</td>\n",
       "      <td>4</td>\n",
       "      <td>20052206</td>\n",
       "      <td>/mnt/d/Maestría/Tesis/Repo/data/data_out/size5...</td>\n",
       "      <td>1069.78280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49170</th>\n",
       "      <td>062742111_7</td>\n",
       "      <td>(-58.28796110552578, -34.841897393341014)</td>\n",
       "      <td>7</td>\n",
       "      <td>62742111</td>\n",
       "      <td>/mnt/d/Maestría/Tesis/Repo/data/data_out/size5...</td>\n",
       "      <td>375.83432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12152</th>\n",
       "      <td>020052012_2</td>\n",
       "      <td>(-58.4113188959935, -34.634505866406684)</td>\n",
       "      <td>2</td>\n",
       "      <td>20052012</td>\n",
       "      <td>/mnt/d/Maestría/Tesis/Repo/data/data_out/size5...</td>\n",
       "      <td>939.56525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87413</th>\n",
       "      <td>065602406_6</td>\n",
       "      <td>(-58.80384279288325, -34.65644168159463)</td>\n",
       "      <td>6</td>\n",
       "      <td>65602406</td>\n",
       "      <td>/mnt/d/Maestría/Tesis/Repo/data/data_out/size5...</td>\n",
       "      <td>590.64386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11569 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                       point  sample  \\\n",
       "25521  020121101_8   (-58.47859271375325, -34.571505645575606)       8   \n",
       "39824  060283915_2   (-58.36645586727871, -34.890629245300666)       2   \n",
       "64391  064274406_2  (-58.570124123271434, -34.678458147020805)       2   \n",
       "19248  020090612_7     (-58.49770402766182, -34.6505026763707)       7   \n",
       "17925  020080907_6    (-58.47890874375637, -34.69102782934132)       6   \n",
       "...            ...                                         ...     ...   \n",
       "51318  063711609_5   (-58.58515157423012, -34.540520500982936)       5   \n",
       "12320  020052206_4    (-58.42173486312725, -34.63288663366313)       4   \n",
       "49170  062742111_7   (-58.28796110552578, -34.841897393341014)       7   \n",
       "12152  020052012_2    (-58.4113188959935, -34.634505866406684)       2   \n",
       "87413  065602406_6    (-58.80384279288325, -34.65644168159463)       6   \n",
       "\n",
       "           link                                              image         var  \n",
       "25521  20121101  /mnt/d/Maestría/Tesis/Repo/data/data_out/size5...  1331.56750  \n",
       "39824  60283915  /mnt/d/Maestría/Tesis/Repo/data/data_out/size5...   440.83040  \n",
       "64391  64274406  /mnt/d/Maestría/Tesis/Repo/data/data_out/size5...   679.80255  \n",
       "19248  20090612  /mnt/d/Maestría/Tesis/Repo/data/data_out/size5...  1037.93380  \n",
       "17925  20080907  /mnt/d/Maestría/Tesis/Repo/data/data_out/size5...  1048.67290  \n",
       "...         ...                                                ...         ...  \n",
       "51318  63711609  /mnt/d/Maestría/Tesis/Repo/data/data_out/size5...   573.58120  \n",
       "12320  20052206  /mnt/d/Maestría/Tesis/Repo/data/data_out/size5...  1069.78280  \n",
       "49170  62742111  /mnt/d/Maestría/Tesis/Repo/data/data_out/size5...   375.83432  \n",
       "12152  20052012  /mnt/d/Maestría/Tesis/Repo/data/data_out/size5...   939.56525  \n",
       "87413  65602406  /mnt/d/Maestría/Tesis/Repo/data/data_out/size5...   590.64386  \n",
       "\n",
       "[11569 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'/mnt/d/Maestr\\xc3\\xada/Tesis/Repo/data/data_out/size512_sample10/020121101_8.npy'\n",
      " b'/mnt/d/Maestr\\xc3\\xada/Tesis/Repo/data/data_out/size512_sample10/060283915_2.npy'\n",
      " b'/mnt/d/Maestr\\xc3\\xada/Tesis/Repo/data/data_out/size512_sample10/064274406_2.npy'\n",
      " ...\n",
      " b'/mnt/d/Maestr\\xc3\\xada/Tesis/Repo/data/data_out/size512_sample10/062742111_7.npy'\n",
      " b'/mnt/d/Maestr\\xc3\\xada/Tesis/Repo/data/data_out/size512_sample10/020052012_2.npy'\n",
      " b'/mnt/d/Maestr\\xc3\\xada/Tesis/Repo/data/data_out/size512_sample10/065602406_6.npy'], shape=(11569,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "filenames = tf.constant(val[\"image\"].to_list())\n",
    "if kind == \"reg\":\n",
    "    labels = tf.constant(val[\"var\"].to_list())\n",
    "elif kind == \"cla\":\n",
    "    labels = tf.one_hot(\n",
    "        (df[\"var\"] - 1).to_list(), 10\n",
    "    )  # Fist class corresponds to decile 1, etc.\n",
    "print(filenames)\n",
    "# print(labels)\n",
    "# Create a dataset from the filenames and labels\n",
    "dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "dataset = dataset.map(\n",
    "    img_file_to_tensor\n",
    ")  # Parse every image in the dataset using `map`\n",
    "datasets += [dataset]\n",
    "\n",
    "# Store filenames for later use\n",
    "filenames_l += [val[\"image\"].to_list()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################################\n",
      "Running model (reg)\n",
      "#######################################################\n",
      "tf.Tensor(\n",
      "[b'/mnt/d/Maestr\\xc3\\xada/Tesis/Repo/data/data_out/size512_sample10/062740311_0.npy'\n",
      " b'/mnt/d/Maestr\\xc3\\xada/Tesis/Repo/data/data_out/size512_sample10/066584112_4.npy'\n",
      " b'/mnt/d/Maestr\\xc3\\xada/Tesis/Repo/data/data_out/size512_sample10/064342306_3.npy'\n",
      " ...\n",
      " b'/mnt/d/Maestr\\xc3\\xada/Tesis/Repo/data/data_out/size512_sample10/064270909_5.npy'\n",
      " b'/mnt/d/Maestr\\xc3\\xada/Tesis/Repo/data/data_out/size512_sample10/063710608_7.npy'\n",
      " b'/mnt/d/Maestr\\xc3\\xada/Tesis/Repo/data/data_out/size512_sample10/064080505_9.npy'], shape=(92549,), dtype=string)\n",
      "tf.Tensor(\n",
      "[b'/mnt/d/Maestr\\xc3\\xada/Tesis/Repo/data/data_out/size512_sample10/020051403_9.npy'\n",
      " b'/mnt/d/Maestr\\xc3\\xada/Tesis/Repo/data/data_out/size512_sample10/065391909_1.npy'\n",
      " b'/mnt/d/Maestr\\xc3\\xada/Tesis/Repo/data/data_out/size512_sample10/066582301_3.npy'\n",
      " ...\n",
      " b'/mnt/d/Maestr\\xc3\\xada/Tesis/Repo/data/data_out/size512_sample10/064901105_0.npy'\n",
      " b'/mnt/d/Maestr\\xc3\\xada/Tesis/Repo/data/data_out/size512_sample10/060351707_1.npy'\n",
      " b'/mnt/d/Maestr\\xc3\\xada/Tesis/Repo/data/data_out/size512_sample10/060350907_0.npy'], shape=(11569,), dtype=string)\n",
      "tf.Tensor(\n",
      "[b'/mnt/d/Maestr\\xc3\\xada/Tesis/Repo/data/data_out/size512_sample10/020121101_8.npy'\n",
      " b'/mnt/d/Maestr\\xc3\\xada/Tesis/Repo/data/data_out/size512_sample10/060283915_2.npy'\n",
      " b'/mnt/d/Maestr\\xc3\\xada/Tesis/Repo/data/data_out/size512_sample10/064274406_2.npy'\n",
      " ...\n",
      " b'/mnt/d/Maestr\\xc3\\xada/Tesis/Repo/data/data_out/size512_sample10/062742111_7.npy'\n",
      " b'/mnt/d/Maestr\\xc3\\xada/Tesis/Repo/data/data_out/size512_sample10/020052012_2.npy'\n",
      " b'/mnt/d/Maestr\\xc3\\xada/Tesis/Repo/data/data_out/size512_sample10/065602406_6.npy'], shape=(11569,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print(\"#######################################################\")\n",
    "print(f\"Running model ({kind})\")\n",
    "print(\"#######################################################\")\n",
    "\n",
    "\n",
    "#### BUILD DATASET\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Train, validation and test split\n",
    "train, test = train_test_split(df, test_size=0.2, shuffle=True, random_state=825)\n",
    "test, val = train_test_split(test, test_size=0.5, shuffle=True, random_state=528)\n",
    "len_test = len(test)\n",
    "\n",
    "assert pd.concat([train, test, val]).sort_index().equals(df)\n",
    "\n",
    "### dataframes to tf.data.Dataset\n",
    "\n",
    "def img_file_to_tensor(file, label):\n",
    "    def _img_file_to_tensor(file, label):\n",
    "        # im = tf.image.decode_jpeg(tf.io.read_file(file), channels=4) # OLD: chequear si funca el nuevo\n",
    "        im = np.load(file)\n",
    "        im = tf.image.resize(im, [224, 224])\n",
    "        im = tf.cast(im, tf.float32)\n",
    "        label = tf.cast(label, tf.float32)\n",
    "        return im, label\n",
    "\n",
    "    return tf.py_function(\n",
    "        _img_file_to_tensor, [file, label], [tf.float32, tf.float32]\n",
    "    )\n",
    "\n",
    "# Create tf.data pipeline for each dataset\n",
    "datasets = []\n",
    "filenames_l = []\n",
    "for dataframe in [train, test, val]:\n",
    "    # Get list of filenames and corresponding list of labels\n",
    "    filenames = tf.constant(dataframe[\"image\"].to_list())\n",
    "    if kind == \"reg\":\n",
    "        labels = tf.constant(dataframe[\"var\"].to_list())\n",
    "    elif kind == \"cla\":\n",
    "        labels = tf.one_hot(\n",
    "            (df[\"var\"] - 1).to_list(), 10\n",
    "        )  # Fist class corresponds to decile 1, etc.\n",
    "    print(filenames)\n",
    "    # print(labels)\n",
    "    # Create a dataset from the filenames and labels\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "    dataset = dataset.map(\n",
    "        img_file_to_tensor\n",
    "    )  # Parse every image in the dataset using `map`\n",
    "    datasets += [dataset]\n",
    "\n",
    "    # Store filenames for later use\n",
    "    filenames_l += [dataframe[\"image\"].to_list()]\n",
    "\n",
    "train_dataset, test_dataset, val_dataset = datasets\n",
    "filenames = {\"train\": filenames_l[0], \"test\": filenames_l[1], \"val\": filenames_l[2]}\n",
    "\n",
    "### augmentations, batching and prefetching\n",
    "# Create a data augmentation stage with horizontal flipping, rotations, zooms\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\n",
    "            \"horizontal_and_vertical\", seed=825, input_shape=(224, 224, 3)\n",
    "        ),\n",
    "        layers.RandomRotation(0.3, fill_mode=\"reflect\", seed=825),\n",
    "        layers.RandomTranslation(0.3, 0.3, fill_mode=\"reflect\", seed=825),\n",
    "        layers.RandomHeight(0.3),\n",
    "        layers.RandomWidth(0.3),\n",
    "        layers.RandomZoom(0.3, seed=825),\n",
    "        layers.RandomContrast(0.3, seed=825),\n",
    "        layers.RandomBrightness(0.4, seed=825),\n",
    "        layers.RandomCrop(224, 224, seed=825),\n",
    "        layers.Resizing(224, 224),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "\n",
    "# Prepare dataset for training\n",
    "train_dataset = (\n",
    "    train_dataset.shuffle(round(len(filenames_l[0]) / 10))\n",
    "    .batch(64)\n",
    "    .map(lambda x, y: (data_augmentation(x), y))\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "test_dataset = test_dataset.batch(64)\n",
    "val_dataset = val_dataset.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(512, 512, 4), dtype=uint8, numpy=\n",
       "array([[[14, 14, 14, 26],\n",
       "        [15, 15, 15, 28],\n",
       "        [16, 16, 16, 28],\n",
       "        ...,\n",
       "        [24, 20, 16, 41],\n",
       "        [23, 18, 14, 37],\n",
       "        [20, 16, 13, 31]],\n",
       "\n",
       "       [[16, 15, 15, 30],\n",
       "        [17, 16, 15, 30],\n",
       "        [17, 16, 15, 30],\n",
       "        ...,\n",
       "        [22, 18, 15, 38],\n",
       "        [21, 17, 13, 33],\n",
       "        [17, 14, 10, 26]],\n",
       "\n",
       "       [[17, 15, 14, 30],\n",
       "        [17, 15, 14, 30],\n",
       "        [17, 15, 14, 29],\n",
       "        ...,\n",
       "        [17, 14, 11, 28],\n",
       "        [15, 12, 10, 24],\n",
       "        [12, 10,  8, 19]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[22, 24, 19, 47],\n",
       "        [30, 33, 26, 59],\n",
       "        [36, 38, 30, 65],\n",
       "        ...,\n",
       "        [36, 30, 26, 46],\n",
       "        [32, 27, 23, 41],\n",
       "        [26, 23, 20, 34]],\n",
       "\n",
       "       [[36, 37, 29, 65],\n",
       "        [42, 43, 35, 71],\n",
       "        [44, 45, 36, 70],\n",
       "        ...,\n",
       "        [27, 22, 19, 35],\n",
       "        [25, 21, 18, 33],\n",
       "        [22, 19, 17, 29]],\n",
       "\n",
       "       [[45, 44, 35, 71],\n",
       "        [47, 46, 37, 70],\n",
       "        [48, 47, 38, 68],\n",
       "        ...,\n",
       "        [22, 18, 16, 29],\n",
       "        [22, 18, 16, 29],\n",
       "        [21, 18, 16, 28]]], dtype=uint8)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = np.load(b'/mnt/d/Maestr\\xc3\\xada/Tesis/Repo/data/data_out/size512_sample10/062740311_0.npy')\n",
    "im = np.moveaxis(im, 0, 2) # Move axis so the original [4, 512, 512] becames [512, 512, 4]\n",
    "im = tf.cast(im, tf.uint8)\n",
    "im\n",
    "# im = tf.cast(im, tf.uint8)\n",
    "# label = tf.cast(label, tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'size' must be a 1-D Tensor of 2 elements: new_height, new_width",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m im \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/mnt/d/Maestr\u001b[39m\u001b[39m\\xc3\u001b[39;00m\u001b[39m\\xad\u001b[39;00m\u001b[39ma/Tesis/Repo/data/data_out/size512_sample10/062740311_0.npy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m im \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mresize(im, [\u001b[39m4\u001b[39;49m, \u001b[39m224\u001b[39;49m, \u001b[39m224\u001b[39;49m])\n\u001b[1;32m      3\u001b[0m im \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcast(im, tf\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m      4\u001b[0m im\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/image_ops_impl.py:1459\u001b[0m, in \u001b[0;36m_resize_images_common\u001b[0;34m(images, resizer_fn, size, preserve_aspect_ratio, name, skip_resize_if_same)\u001b[0m\n\u001b[1;32m   1457\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39msize\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m must be a 1-D int32 Tensor\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1458\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m size\u001b[39m.\u001b[39mget_shape()\u001b[39m.\u001b[39mis_compatible_with([\u001b[39m2\u001b[39m]):\n\u001b[0;32m-> 1459\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39msize\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m must be a 1-D Tensor of 2 elements: \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1460\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mnew_height, new_width\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1462\u001b[0m \u001b[39mif\u001b[39;00m preserve_aspect_ratio:\n\u001b[1;32m   1463\u001b[0m   \u001b[39m# Get the current shapes of the image, even if dynamic.\u001b[39;00m\n\u001b[1;32m   1464\u001b[0m   _, current_height, current_width, _ \u001b[39m=\u001b[39m _ImageDimensions(images, rank\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: 'size' must be a 1-D Tensor of 2 elements: new_height, new_width"
     ]
    }
   ],
   "source": [
    "im = np.load(b'/mnt/d/Maestr\\xc3\\xada/Tesis/Repo/data/data_out/size512_sample10/062740311_0.npy')\n",
    "im = tf.image.resize(im, [224, 224])\n",
    "im = tf.cast(im, tf.float32)\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/nico/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Channels:\n",
      " - defaults\n",
      " - conda-forge\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - sklearn\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - defaults\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install sklearn -y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/nico/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Collecting tensorflow_addons\n",
      "  Obtaining dependency information for tensorflow_addons from https://files.pythonhosted.org/packages/c5/77/28e090b43f802f321c07f6c553bdba79e5ce38fab784c2cd924ff28cfcb0/tensorflow_addons-0.21.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading tensorflow_addons-0.21.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: packaging in /home/nico/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow_addons) (23.1)\n",
      "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Downloading tensorflow_addons-0.21.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (612 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m612.1/612.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: typeguard, tensorflow_addons\n",
      "Successfully installed tensorflow_addons-0.21.0 typeguard-2.13.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_addons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/nico/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: matplotlib in /home/nico/miniconda3/envs/tf/lib/python3.9/site-packages (3.7.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/nico/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/nico/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/nico/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (4.41.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/nico/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/nico/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/nico/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/nico/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (10.0.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /home/nico/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/nico/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/nico/miniconda3/envs/tf/lib/python3.9/site-packages (from matplotlib) (6.0.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/nico/miniconda3/envs/tf/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.16.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/nico/miniconda3/envs/tf/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.isdir(r\"/mnt/d/Maestría/Tesis/Repo/data/data_out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/d/Maestría/Tesis/Repo/data/data_out/size512_sample5/size512_sample5_chunk0.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m np\u001b[39m.\u001b[39;49mload(\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/mnt/d/Maestría/Tesis/Repo/data/data_out/size512_sample5/size512_sample5_chunk0.npz\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/numpy/lib/npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    406\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/d/Maestría/Tesis/Repo/data/data_out/size512_sample5/size512_sample5_chunk0.npz'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.load(r\"/mnt/d/Maestría/Tesis/Repo/data/data_out/size512_sample5/size512_sample5_chunk0.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 57\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[39m# the next 3 lines of code are for my machine and setup due to https://github.com/tensorflow/tensorflow/issues/43174\u001b[39;00m\n\u001b[0;32m     56\u001b[0m physical_devices \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mlist_physical_devices(\u001b[39m\"\u001b[39m\u001b[39mGPU\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 57\u001b[0m tf\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mset_memory_growth(physical_devices[\u001b[39m0\u001b[39;49m], \u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "##############      Configuración      ##############\n",
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "from PIL import Image\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "env = dotenv_values(\"globals.env\")\n",
    "\n",
    "path_proyecto = env[\"PATH_PROYECTO\"]\n",
    "path_datain = env[\"PATH_DATAIN\"]\n",
    "path_dataout = env[\"PATH_DATAOUT\"]\n",
    "path_scripts = env[\"PATH_SCRIPTS\"]\n",
    "path_satelites = env[\"PATH_SATELITES\"]\n",
    "path_logs = env[\"PATH_LOGS\"]\n",
    "path_outputs = env[\"PATH_OUTPUTS\"]\n",
    "# path_programas  = globales[7]\n",
    "###############################################\n",
    "\n",
    "import prediction_tools\n",
    "# import custom_models\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from typing import Iterator, List, Union, Tuple, Any\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# import tensorflow_addons as tfa\n",
    "\n",
    "from tensorflow.keras import layers, models, Model\n",
    "from tensorflow.python.keras.callbacks import (\n",
    "    TensorBoard,\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications import (\n",
    "    MobileNetV3Small,\n",
    "    EfficientNetB0,\n",
    "    EfficientNetV2B0,\n",
    ")\n",
    "\n",
    "# the next 3 lines of code are for my machine and setup due to https://github.com/tensorflow/tensorflow/issues/43174\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physical_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R:/Tesis Nico\\Códigos\\scripts\\Testing - Deep Learning con MapTilesDownloader\n",
      "El directorio en scripts existe. Creando carpetas.\n",
      "R:/Tesis Nico\\Códigos\\data ya existe\n",
      "R:/Tesis Nico\\Códigos\\data\\data_in ya existe\n",
      "R:/Tesis Nico\\Códigos\\data\\data_out ya existe\n",
      "R:/Tesis Nico\\Códigos\\data\\data_out\\Testing - Deep Learning con MapTilesDownloader ya existe\n",
      "R:/Tesis Nico\\Códigos\\docs ya existe\n",
      "R:/Tesis Nico\\Códigos\\scripts ya existe\n",
      "R:/Tesis Nico\\Códigos\\scripts\\Testing - Deep Learning con MapTilesDownloader ya existe\n",
      "R:/Tesis Nico\\Códigos\\outputs ya existe\n",
      "R:/Tesis Nico\\Códigos\\outputs\\figures ya existe\n",
      "R:/Tesis Nico\\Códigos\\outputs\\figures\\Testing - Deep Learning con MapTilesDownloader ya existe\n",
      "R:/Tesis Nico\\Códigos\\outputs\\maps ya existe\n",
      "R:/Tesis Nico\\Códigos\\outputs\\maps\\Testing - Deep Learning con MapTilesDownloader ya existe\n",
      "R:/Tesis Nico\\Códigos\\outputs\\tables ya existe\n",
      "R:/Tesis Nico\\Códigos\\outputs\\tables\\Testing - Deep Learning con MapTilesDownloader ya existe\n"
     ]
    }
   ],
   "source": [
    "##############      Configuración      ##############\n",
    "import gc, sys, os\n",
    "\n",
    "from dotenv import dotenv_values\n",
    "from plantilla import plantilla\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "import cartopy.crs as crs\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "from matplotlib.figure import Figure\n",
    "from shapely.geometry import box\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "parte = 1\n",
    "total_partes = 8\n",
    "map_name = \"GMaps\"\n",
    "\n",
    "env = dotenv_values(\n",
    "    r\"R:\\Tesis Nico\\Códigos\\scripts\\Testing - Deep Learning con MapTilesDownloader\\globals.env\"\n",
    ")\n",
    "\n",
    "proyecto = \"Códigos\"\n",
    "subproyecto = \"Testing - Deep Learning con MapTilesDownloader\"\n",
    "\n",
    "globales = plantilla(\n",
    "    proyecto=proyecto, subproyecto=subproyecto, path_proyectos=env[\"PATH_PROYECTOS\"]\n",
    ")\n",
    "\n",
    "path_proyecto = globales[0]  # Ubicación de la carpeta del Proyecto\n",
    "path_datain = globales[1]\n",
    "path_dataout = globales[2]  # Bases procesadas por tus scripts\n",
    "path_scripts = globales[3]\n",
    "path_figures = globales[4]  # Output para las figuras/gráficos\n",
    "path_maps = globales[5]  # Output para los mapas (html o imagen)\n",
    "path_tables = globales[6]  # Output para las tablas (imagen o excel)\n",
    "path_programas = globales[7]\n",
    "\n",
    "\n",
    "icpag = gpd.read_file(\n",
    "    r\"R:\\Shapefiles\\ICPAG\\Sin barrios pop y cerr\\Aglomerados de mas de 500k habitantes\\base_icpag_500k.shp\"\n",
    ")\n",
    "icpag = icpag.to_crs(epsg=3857)\n",
    "\n",
    "if map_name == \"ESRI\":\n",
    "    map_provider = cimgt.GoogleTiles(\n",
    "        url=\"https://services.arcgisonline.com/arcgis/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}\"\n",
    "    )\n",
    "elif map_name == \"GMaps\":\n",
    "    map_provider = cimgt.GoogleTiles(style=\"satellite\")\n",
    "else:\n",
    "    raise ValueError(\"map_provider debe ser ESRI o GMaps\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = icpag\n",
    "test.geometry = test.centroid.buffer(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# icpag.geometry = icpag.centroid.buffer(100)\n",
    "\n",
    "def random_point_from_geometry(gdf_slice):\n",
    "    \"\"\"Generates a random point within the bounds of a GeoDataFrame.\"\"\"\n",
    "\n",
    "    gdf_slice = gdf_slice.copy()\n",
    "\n",
    "    # Get bounds of the shapefile's polygon\n",
    "    bbox = gdf_slice.bounds\n",
    "\n",
    "    while 0 == 0:\n",
    "        # generate random data within the bounds\n",
    "        x = np.random.uniform(bbox[\"minx\"], bbox[\"maxx\"], 1)\n",
    "        y = np.random.uniform(bbox[\"miny\"], bbox[\"maxy\"], 1)\n",
    "\n",
    "        # convert them to a points GeoSeries\n",
    "        gdf_points = gpd.GeoSeries(gpd.points_from_xy(x, y))\n",
    "        # only keep those points within polygons\n",
    "        gdf_points = gdf_points[gdf_points.within(gdf_slice.unary_union)]\n",
    "        if len(gdf_points) > 0: \n",
    "            # If one point is found, stop the loop\n",
    "            break\n",
    "\n",
    "    gdf_slice = gdf_slice.drop(columns=\"geometry\")\n",
    "    gdf_slice = gpd.GeoDataFrame(gdf_slice, geometry=gpd.points_from_xy(x, y))\n",
    "    gdf_slice = gdf_slice.set_crs(epsg=3857)\n",
    "    gdf_slice.geometry = gdf_slice.centroid.buffer(100)\n",
    "\n",
    "    return gdf_slice\n",
    "\n",
    "\n",
    "def create_map_from_geometry(\n",
    "    icpag,\n",
    "    index,\n",
    "    map_provider=map_provider,\n",
    "    zoom=18,\n",
    "    map_name=\"ESRI_WI\",\n",
    "    path_output=path_datain,\n",
    "    sample_size=1,\n",
    "    my_dpi=96,\n",
    "):\n",
    "\n",
    "    \"\"\"Exporto imgs de 512x512.\n",
    "\n",
    "    Matplotlib doesn't work with pixels directly, but rather physical sizes and DPI.\n",
    "    If you want to display a figure with a certain pixel size, you need to know the DPI of your monitor.\n",
    "    For example this link (https://www.infobyip.com/detectmonitordpi.php) will detect that for you.\n",
    "    \"\"\"\n",
    "    # FIXME: le cambié el rqange a 1 temporalmente, borrar la prox que lo corra\n",
    "    for i in range(1, sample_size + 1):\n",
    "        try:\n",
    "            # Reduzco el polygono para que sea aprox una manzana\n",
    "            polygon = random_point_from_geometry(icpag.iloc[index : index + 1, :])\n",
    "            # polygon = icpag.iloc[index : index + 1, :]\n",
    "\n",
    "            # Genero la máscara para el gráfico y obtengo el extent\n",
    "            link = polygon.at[index, \"link\"]\n",
    "            bbox = polygon.bounds\n",
    "            geom = box(*bbox.values[0])\n",
    "            mask = polygon.copy()\n",
    "            mask[\"geometry\"] = geom\n",
    "\n",
    "            # Gráfico\n",
    "            # The pylab figure manager will be bypassed in this instance.\n",
    "            # This means that `fig` will be garbage collected as you'd expect.\n",
    "            fig = Figure(dpi=my_dpi, figsize=(512 / my_dpi, 512 / my_dpi), linewidth=0)\n",
    "            ax = fig.add_axes(\n",
    "                [0, 0, 1, 1], projection=crs.epsg(3857), facecolor=\"black\"\n",
    "            )\n",
    "\n",
    "            # Limita la visualización a un área determinada\n",
    "            ax.set_extent(\n",
    "                [bbox[\"minx\"], bbox[\"maxx\"], bbox[\"miny\"], bbox[\"maxy\"]],\n",
    "                crs=crs.epsg(3857),\n",
    "            )\n",
    "\n",
    "            # Agrego mapa de fondo\n",
    "            ax.add_image(map_provider, zoom)\n",
    "\n",
    "            # Quito bordes y grilla\n",
    "            ax.set(frame_on=False)\n",
    "\n",
    "            # # Añade la máscara\n",
    "            # mask.difference(polygon).plot(ax=ax, facecolor='black', edgecolor='black', linewidth=0.0)\n",
    "            # fig.add_axes(ax)\n",
    "\n",
    "            fig.savefig(\n",
    "                rf\"{path_datain}\\argentina_full_512\\{map_name}_{link}_{index}_{i}.jpg\",\n",
    "                dpi=my_dpi,\n",
    "            )\n",
    "            del fig\n",
    "            gc.collect()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.6.0/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-1.12.4.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.6.0/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap-theme.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_4d2b56edc9e5093fdeabdefb1cebdb88 {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "    \n",
       "                    &lt;style&gt;\n",
       "                        .foliumtooltip {\n",
       "                            \n",
       "                        }\n",
       "                       .foliumtooltip table{\n",
       "                            margin: auto;\n",
       "                        }\n",
       "                        .foliumtooltip tr{\n",
       "                            text-align: left;\n",
       "                        }\n",
       "                        .foliumtooltip th{\n",
       "                            padding: 2px; padding-right: 8px;\n",
       "                        }\n",
       "                    &lt;/style&gt;\n",
       "            \n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_4d2b56edc9e5093fdeabdefb1cebdb88&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_4d2b56edc9e5093fdeabdefb1cebdb88 = L.map(\n",
       "                &quot;map_4d2b56edc9e5093fdeabdefb1cebdb88&quot;,\n",
       "                {\n",
       "                    center: [-34.58649831810719, -58.36927572150936],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    zoom: 10,\n",
       "                    zoomControl: true,\n",
       "                    preferCanvas: false,\n",
       "                }\n",
       "            );\n",
       "            L.control.scale().addTo(map_4d2b56edc9e5093fdeabdefb1cebdb88);\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_cc9404434f09bb4a3959a77779efde6b = L.tileLayer(\n",
       "                &quot;https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
       "                {&quot;attribution&quot;: &quot;Data by \\u0026copy; \\u003ca href=\\&quot;http://openstreetmap.org\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e, under \\u003ca href=\\&quot;http://www.openstreetmap.org/copyright\\&quot;\\u003eODbL\\u003c/a\\u003e.&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 18, &quot;maxZoom&quot;: 18, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            ).addTo(map_4d2b56edc9e5093fdeabdefb1cebdb88);\n",
       "        \n",
       "    \n",
       "            map_4d2b56edc9e5093fdeabdefb1cebdb88.fitBounds(\n",
       "                [[-34.58723787427248, -58.37017403679348], [-34.5857587619419, -58.36837740622524]],\n",
       "                {}\n",
       "            );\n",
       "        \n",
       "    \n",
       "        function geo_json_cfdf32dd98915b607bbddf51aea2117b_styler(feature) {\n",
       "            switch(feature.id) {\n",
       "                default:\n",
       "                    return {&quot;fillOpacity&quot;: 0.5, &quot;weight&quot;: 2};\n",
       "            }\n",
       "        }\n",
       "        function geo_json_cfdf32dd98915b607bbddf51aea2117b_highlighter(feature) {\n",
       "            switch(feature.id) {\n",
       "                default:\n",
       "                    return {&quot;fillOpacity&quot;: 0.75};\n",
       "            }\n",
       "        }\n",
       "        function geo_json_cfdf32dd98915b607bbddf51aea2117b_pointToLayer(feature, latlng) {\n",
       "            var opts = {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: true, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 2, &quot;stroke&quot;: true, &quot;weight&quot;: 3};\n",
       "            \n",
       "            let style = geo_json_cfdf32dd98915b607bbddf51aea2117b_styler(feature)\n",
       "            Object.assign(opts, style)\n",
       "            \n",
       "            return new L.CircleMarker(latlng, opts)\n",
       "        }\n",
       "\n",
       "        function geo_json_cfdf32dd98915b607bbddf51aea2117b_onEachFeature(feature, layer) {\n",
       "            layer.on({\n",
       "                mouseout: function(e) {\n",
       "                    if(typeof e.target.setStyle === &quot;function&quot;){\n",
       "                        geo_json_cfdf32dd98915b607bbddf51aea2117b.resetStyle(e.target);\n",
       "                    }\n",
       "                },\n",
       "                mouseover: function(e) {\n",
       "                    if(typeof e.target.setStyle === &quot;function&quot;){\n",
       "                        const highlightStyle = geo_json_cfdf32dd98915b607bbddf51aea2117b_highlighter(e.target.feature)\n",
       "                        e.target.setStyle(highlightStyle);\n",
       "                    }\n",
       "                },\n",
       "            });\n",
       "        };\n",
       "        var geo_json_cfdf32dd98915b607bbddf51aea2117b = L.geoJson(null, {\n",
       "                onEachFeature: geo_json_cfdf32dd98915b607bbddf51aea2117b_onEachFeature,\n",
       "            \n",
       "                style: geo_json_cfdf32dd98915b607bbddf51aea2117b_styler,\n",
       "                pointToLayer: geo_json_cfdf32dd98915b607bbddf51aea2117b_pointToLayer\n",
       "        });\n",
       "\n",
       "        function geo_json_cfdf32dd98915b607bbddf51aea2117b_add (data) {\n",
       "            geo_json_cfdf32dd98915b607bbddf51aea2117b\n",
       "                .addData(data)\n",
       "                .addTo(map_4d2b56edc9e5093fdeabdefb1cebdb88);\n",
       "        }\n",
       "            geo_json_cfdf32dd98915b607bbddf51aea2117b_add({&quot;bbox&quot;: [-58.37017403679348, -34.58723787427248, -58.36837740622524, -34.5857587619419], &quot;features&quot;: [{&quot;bbox&quot;: [-58.37017403679348, -34.58723787427248, -58.36837740622524, -34.5857587619419], &quot;geometry&quot;: {&quot;coordinates&quot;: [[[-58.36837740622524, -34.58649832139819], [-58.36838173185887, -34.58657081054701], [-58.368394667101526, -34.586642601523366], [-58.36841608737978, -34.58671300294363], [-58.368445786404614, -34.586781336808], [-58.368483478158204, -34.5868469450299], [-58.36852879964835, -34.58690919577349], [-58.368581314404324, -34.58696748953823], [-58.368640516680315, -34.58702126493224], [-58.36870583632605, -34.587070004078285], [-58.36877664427764, -34.58711323760102], [-58.36885225861578, -34.58715054914685], [-58.36893195113309, -34.5871815793934], [-58.36901495434704, -34.587206029509616], [-58.369100468891304, -34.587223664033395], [-58.36918767121409, -34.58723431313902], [-58.369275721509354, -34.58723787427248], [-58.36936377180463, -34.58723431313902], [-58.36945097412741, -34.587223664033395], [-58.36953648867167, -34.587206029509616], [-58.369619491885636, -34.5871815793934], [-58.36969918440294, -34.58715054914685], [-58.36977479874108, -34.58711323760102], [-58.36984560669267, -34.587070004078285], [-58.369910926338406, -34.58702126493224], [-58.3699701286144, -34.58696748953823], [-58.37002264337037, -34.58690919577349], [-58.37006796486052, -34.5868469450299], [-58.37010565661409, -34.586781336808], [-58.37013535563894, -34.58671300294363], [-58.37015677591718, -34.586642601523366], [-58.37016971115985, -34.58657081054701], [-58.37017403679348, -34.58649832139819], [-58.37016971115985, -34.58642583218613], [-58.37015677591718, -34.586354041022496], [-58.37013535563894, -34.58628363929812], [-58.37010565661409, -34.58621530502446], [-58.37006796486052, -34.58614969630385], [-58.37002264337037, -34.58608744499131], [-58.3699701286144, -34.586029150609185], [-58.369910926338406, -34.58597537457314], [-58.36984560669267, -34.58592663478504], [-58.36977479874108, -34.585883400644946], [-58.36969918440294, -34.58584608853015], [-58.369619491885636, -34.58581505778488], [-58.36953648867167, -34.58579060725939], [-58.36945097412741, -34.5857729724315], [-58.36936377180463, -34.58576232313859], [-58.369275721509354, -34.5857587619419], [-58.36918767121409, -34.58576232313859], [-58.369100468891304, -34.5857729724315], [-58.36901495434704, -34.58579060725939], [-58.36893195113309, -34.58581505778488], [-58.36885225861578, -34.58584608853015], [-58.36877664427764, -34.585883400644946], [-58.36870583632605, -34.58592663478504], [-58.368640516680315, -34.58597537457314], [-58.368581314404324, -34.586029150609185], [-58.36852879964835, -34.58608744499131], [-58.368483478158204, -34.58614969630385], [-58.368445786404614, -34.58621530502446], [-58.36841608737978, -34.58628363929812], [-58.368394667101526, -34.586354041022496], [-58.36838173185887, -34.58642583218613], [-58.36837740622524, -34.58649832139819]]], &quot;type&quot;: &quot;Polygon&quot;}, &quot;id&quot;: &quot;0&quot;, &quot;properties&quot;: {&quot;AMBA_legal&quot;: 1, &quot;AREA&quot;: 1810711.75, &quot;CicpagNv&quot;: 30.0, &quot;CicvNp&quot;: 46.0, &quot;CicvNr&quot;: 42.0, &quot;CicvNv&quot;: 37.0, &quot;CicvPp&quot;: 8.0, &quot;CicvPr&quot;: 6.0, &quot;CicvPv&quot;: 4.0, &quot;CrmaxNp&quot;: 49.0, &quot;CrmaxNr&quot;: 48.0, &quot;CrmaxNv&quot;: 39.0, &quot;CrmaxPp&quot;: 6.0, &quot;CrmaxPr&quot;: 4.0, &quot;CrmaxPv&quot;: 3.0, &quot;Crmaxp25Np&quot;: 67.0, &quot;Crmaxp25Nr&quot;: 66.0, &quot;Crmaxp25Nv&quot;: 57.0, &quot;Crmaxp25Pp&quot;: 8.0, &quot;Crmaxp25Pr&quot;: 6.0, &quot;Crmaxp25Pv&quot;: 4.0, &quot;Crmaxp50Np&quot;: 20.0, &quot;Crmaxp50Nr&quot;: 22.0, &quot;Crmaxp50Nv&quot;: 15.0, &quot;Crmaxp50Pp&quot;: 1.0, &quot;Crmaxp50Pr&quot;: 1.0, &quot;Crmaxp50Pv&quot;: 1.0, &quot;Crmaxp75Np&quot;: 12.0, &quot;Crmaxp75Nr&quot;: 14.0, &quot;Crmaxp75Nv&quot;: 9.0, &quot;Crmaxp75Pp&quot;: 1.0, &quot;Crmaxp75Pr&quot;: 1.0, &quot;Crmaxp75Pv&quot;: 1.0, &quot;DEPTO&quot;: 1, &quot;FRAC&quot;: 1, &quot;PAISXRAD10&quot;: 31605, &quot;PAISXRAD_1&quot;: 31605, &quot;PERIMETER&quot;: 14528.932, &quot;PROV&quot;: 2, &quot;RADIO&quot;: 1, &quot;TIPO&quot;: &quot;U&quot;, &quot;aglo_eph&quot;: 1, &quot;aglomerado&quot;: &quot;Gran Buenos Aires&quot;, &quot;basuno&quot;: 207.0, &quot;basusi&quot;: 0.0, &quot;basutotal&quot;: 207.0, &quot;cod_fra&quot;: 200101, &quot;cod_fra_1&quot;: 200101, &quot;codaglo&quot;: 1.0, &quot;con_nbi&quot;: 19, &quot;cprov&quot;: 2.0, &quot;den_p&quot;: 1.87137525473817, &quot;departamen&quot;: &quot;Comuna 1&quot;, &quot;eph_aglome&quot;: &quot;CABA&quot;, &quot;eph_codagl&quot;: 1.0, &quot;f__hacinam&quot;: 36.9047619048, &quot;f__sinretr&quot;: 0.0, &quot;f_edmen1ri&quot;: 7.39130434783, &quot;f_edunv&quot;: 5.65217391304, &quot;f_pobbasu&quot;: 0.0, &quot;f_pobinund&quot;: 61.6071428571, &quot;f_pobvilla&quot;: 0.0, &quot;f_sobsocia&quot;: 20.5357142857, &quot;hacinam&quot;: 124.0, &quot;icpag&quot;: 0.300000011920929, &quot;icpagNabs&quot;: -0.331286311149597, &quot;icv2010&quot;: 6.79219204293, &quot;indbasu&quot;: 1.0, &quot;indedmen1r&quot;: 0.872846421177, &quot;indeduniv&quot;: 0.129390725465, &quot;index&quot;: 0, &quot;indhacinam&quot;: 0.609892465216, &quot;indicetmi&quot;: 0.911244, &quot;indinund&quot;: -0.125450180071, &quot;indobsoc&quot;: 0.739195906963, &quot;indpa&quot;: 0.624849939976, &quot;indsinretr&quot;: 1.00492264416, &quot;indvilla&quot;: 1.0, &quot;inundno&quot;: 0.0, &quot;inundsi&quot;: 207.0, &quot;inundtotal&quot;: 207.0, &quot;link&quot;: 20010101, &quot;link2&quot;: 20010101.0, &quot;link_1&quot;: 20010101, &quot;link_dpto&quot;: 2001, &quot;lvp1bv&quot;: 11.438682556152344, &quot;lvp1bvp50&quot;: 11.29108428955078, &quot;lvpra_1bv&quot;: 11.429780006408691, &quot;lvpra_1bvp&quot;: 11.281265258789062, &quot;lvprf_1bv&quot;: 11.375898361206056, &quot;lvprf_1bvp&quot;: 11.227383613586426, &quot;mergeicv&quot;: 3, &quot;mergelvp&quot;: 3, &quot;mujer&quot;: 0.0, &quot;mujer1&quot;: 124.0, &quot;nbi_rc&quot;: 0.204301074147224, &quot;nbi_rc_val&quot;: 0.292307704687119, &quot;nprov&quot;: 2.0, &quot;objectid&quot;: 49509.0, &quot;objectid_1&quot;: 0.0, &quot;obs_pm2&quot;: 7.0, &quot;obs_pm2_19&quot;: 29.0, &quot;oid_&quot;: 49508.0, &quot;p1305&quot;: 156.0, &quot;p_usd&quot;: 187153.04575892855, &quot;p_usd_2019&quot;: 253498.63333333333, &quot;pa_complem&quot;: 0.0, &quot;personas&quot;: 336.0, &quot;pm2&quot;: 2348.729736328125, &quot;pm2_2019&quot;: 3959.027587890625, &quot;pobhogpart&quot;: 274.0, &quot;poblmenpri&quot;: 17.0, &quot;poblnoasis&quot;: 230.0, &quot;poblsinobr&quot;: 69.0, &quot;provdep&quot;: 2001, &quot;provdep_1&quot;: 2001, &quot;provincia&quot;: &quot;Ciudad Aut\\u00f3noma de Buenos Aires&quot;, &quot;rmax&quot;: 0.279756546020508, &quot;rmaxp25&quot;: 0.594332575798035, &quot;rmaxp50&quot;: 0.086821734905243, &quot;rmaxp75&quot;: 0.009220659732819, &quot;rmin&quot;: 0.663291931152344, &quot;rminp25&quot;: 0.888591051101685, &quot;rminp50&quot;: 0.742911577224731, &quot;rminp75&quot;: 0.531639575958252, &quot;rrbn&quot;: 3.75, &quot;rrsc&quot;: 9.0, &quot;rural1&quot;: 0.0, &quot;rural2&quot;: 0.0, &quot;sin_nbi&quot;: 46, &quot;sinretrete&quot;: 0.0, &quot;superficie&quot;: 1795471.0, &quot;tasa_activ&quot;: 87.56999999999998, &quot;tasa_desoc&quot;: 2.7, &quot;tasa_emple&quot;: 85.20999999999998, &quot;total&quot;: 93, &quot;total_val&quot;: 65.0, &quot;totalpob_1&quot;: 336.0, &quot;totalpobl&quot;: 336.0, &quot;univcompl&quot;: 13.0, &quot;urbano&quot;: 1.0, &quot;varon&quot;: 0.0, &quot;var\\u00a5n&quot;: 212.0, &quot;villano&quot;: 207.0, &quot;villasi&quot;: 0.0, &quot;villatotal&quot;: 207.0, &quot;viv_part&quot;: 80.0}, &quot;type&quot;: &quot;Feature&quot;}], &quot;type&quot;: &quot;FeatureCollection&quot;});\n",
       "\n",
       "        \n",
       "    \n",
       "    geo_json_cfdf32dd98915b607bbddf51aea2117b.bindTooltip(\n",
       "    function(layer){\n",
       "    let div = L.DomUtil.create(&#x27;div&#x27;);\n",
       "    \n",
       "    let handleObject = feature=&gt;typeof(feature)==&#x27;object&#x27; ? JSON.stringify(feature) : feature;\n",
       "    let fields = [&quot;index&quot;, &quot;link&quot;, &quot;AREA&quot;, &quot;PERIMETER&quot;, &quot;PAISXRAD10&quot;, &quot;PAISXRAD_1&quot;, &quot;PROV&quot;, &quot;DEPTO&quot;, &quot;FRAC&quot;, &quot;RADIO&quot;, &quot;TIPO&quot;, &quot;link_dpto&quot;, &quot;departamen&quot;, &quot;provincia&quot;, &quot;eph_codagl&quot;, &quot;eph_aglome&quot;, &quot;codaglo&quot;, &quot;aglomerado&quot;, &quot;aglo_eph&quot;, &quot;AMBA_legal&quot;, &quot;rmin&quot;, &quot;rmax&quot;, &quot;rminp50&quot;, &quot;rminp25&quot;, &quot;rminp75&quot;, &quot;rmaxp50&quot;, &quot;rmaxp25&quot;, &quot;rmaxp75&quot;, &quot;p_usd&quot;, &quot;pm2&quot;, &quot;obs_pm2&quot;, &quot;pm2_2019&quot;, &quot;obs_pm2_19&quot;, &quot;p_usd_2019&quot;, &quot;personas&quot;, &quot;viv_part&quot;, &quot;lvp1bvp50&quot;, &quot;lvpra_1bvp&quot;, &quot;lvprf_1bvp&quot;, &quot;lvp1bv&quot;, &quot;lvpra_1bv&quot;, &quot;lvprf_1bv&quot;, &quot;superficie&quot;, &quot;den_p&quot;, &quot;rural1&quot;, &quot;rural2&quot;, &quot;urbano&quot;, &quot;mergelvp&quot;, &quot;objectid_1&quot;, &quot;cod_fra&quot;, &quot;provdep&quot;, &quot;oid_&quot;, &quot;objectid&quot;, &quot;link_1&quot;, &quot;cod_fra_1&quot;, &quot;provdep_1&quot;, &quot;indicetmi&quot;, &quot;rrbn&quot;, &quot;rrsc&quot;, &quot;pa_complem&quot;, &quot;varon&quot;, &quot;mujer&quot;, &quot;totalpobl&quot;, &quot;poblnoasis&quot;, &quot;poblmenpri&quot;, &quot;f_edmen1ri&quot;, &quot;indedmen1r&quot;, &quot;univcompl&quot;, &quot;f_edunv&quot;, &quot;indeduniv&quot;, &quot;pobhogpart&quot;, &quot;hacinam&quot;, &quot;f__hacinam&quot;, &quot;indhacinam&quot;, &quot;sinretrete&quot;, &quot;f__sinretr&quot;, &quot;indsinretr&quot;, &quot;poblsinobr&quot;, &quot;inundsi&quot;, &quot;inundno&quot;, &quot;inundtotal&quot;, &quot;basusi&quot;, &quot;basuno&quot;, &quot;basutotal&quot;, &quot;villasi&quot;, &quot;villano&quot;, &quot;villatotal&quot;, &quot;var\\u00a5n&quot;, &quot;mujer1&quot;, &quot;totalpob_1&quot;, &quot;f_pobinund&quot;, &quot;f_pobbasu&quot;, &quot;f_pobvilla&quot;, &quot;indinund&quot;, &quot;indbasu&quot;, &quot;indvilla&quot;, &quot;indpa&quot;, &quot;p1305&quot;, &quot;link2&quot;, &quot;f_sobsocia&quot;, &quot;indobsoc&quot;, &quot;icv2010&quot;, &quot;mergeicv&quot;, &quot;cprov&quot;, &quot;nprov&quot;, &quot;CicvNr&quot;, &quot;CicvNp&quot;, &quot;CicvNv&quot;, &quot;CrmaxNr&quot;, &quot;CrmaxNp&quot;, &quot;CrmaxNv&quot;, &quot;Crmaxp50Nr&quot;, &quot;Crmaxp50Np&quot;, &quot;Crmaxp50Nv&quot;, &quot;Crmaxp25Nr&quot;, &quot;Crmaxp25Np&quot;, &quot;Crmaxp25Nv&quot;, &quot;Crmaxp75Nr&quot;, &quot;Crmaxp75Np&quot;, &quot;Crmaxp75Nv&quot;, &quot;CicvPr&quot;, &quot;CicvPp&quot;, &quot;CicvPv&quot;, &quot;CrmaxPr&quot;, &quot;CrmaxPp&quot;, &quot;CrmaxPv&quot;, &quot;Crmaxp50Pr&quot;, &quot;Crmaxp50Pp&quot;, &quot;Crmaxp50Pv&quot;, &quot;Crmaxp25Pr&quot;, &quot;Crmaxp25Pp&quot;, &quot;Crmaxp25Pv&quot;, &quot;Crmaxp75Pr&quot;, &quot;Crmaxp75Pp&quot;, &quot;Crmaxp75Pv&quot;, &quot;tasa_activ&quot;, &quot;tasa_emple&quot;, &quot;tasa_desoc&quot;, &quot;total&quot;, &quot;total_val&quot;, &quot;con_nbi&quot;, &quot;sin_nbi&quot;, &quot;nbi_rc&quot;, &quot;nbi_rc_val&quot;, &quot;icpagNabs&quot;, &quot;CicpagNv&quot;, &quot;icpag&quot;];\n",
       "    let aliases = [&quot;index&quot;, &quot;link&quot;, &quot;AREA&quot;, &quot;PERIMETER&quot;, &quot;PAISXRAD10&quot;, &quot;PAISXRAD_1&quot;, &quot;PROV&quot;, &quot;DEPTO&quot;, &quot;FRAC&quot;, &quot;RADIO&quot;, &quot;TIPO&quot;, &quot;link_dpto&quot;, &quot;departamen&quot;, &quot;provincia&quot;, &quot;eph_codagl&quot;, &quot;eph_aglome&quot;, &quot;codaglo&quot;, &quot;aglomerado&quot;, &quot;aglo_eph&quot;, &quot;AMBA_legal&quot;, &quot;rmin&quot;, &quot;rmax&quot;, &quot;rminp50&quot;, &quot;rminp25&quot;, &quot;rminp75&quot;, &quot;rmaxp50&quot;, &quot;rmaxp25&quot;, &quot;rmaxp75&quot;, &quot;p_usd&quot;, &quot;pm2&quot;, &quot;obs_pm2&quot;, &quot;pm2_2019&quot;, &quot;obs_pm2_19&quot;, &quot;p_usd_2019&quot;, &quot;personas&quot;, &quot;viv_part&quot;, &quot;lvp1bvp50&quot;, &quot;lvpra_1bvp&quot;, &quot;lvprf_1bvp&quot;, &quot;lvp1bv&quot;, &quot;lvpra_1bv&quot;, &quot;lvprf_1bv&quot;, &quot;superficie&quot;, &quot;den_p&quot;, &quot;rural1&quot;, &quot;rural2&quot;, &quot;urbano&quot;, &quot;mergelvp&quot;, &quot;objectid_1&quot;, &quot;cod_fra&quot;, &quot;provdep&quot;, &quot;oid_&quot;, &quot;objectid&quot;, &quot;link_1&quot;, &quot;cod_fra_1&quot;, &quot;provdep_1&quot;, &quot;indicetmi&quot;, &quot;rrbn&quot;, &quot;rrsc&quot;, &quot;pa_complem&quot;, &quot;varon&quot;, &quot;mujer&quot;, &quot;totalpobl&quot;, &quot;poblnoasis&quot;, &quot;poblmenpri&quot;, &quot;f_edmen1ri&quot;, &quot;indedmen1r&quot;, &quot;univcompl&quot;, &quot;f_edunv&quot;, &quot;indeduniv&quot;, &quot;pobhogpart&quot;, &quot;hacinam&quot;, &quot;f__hacinam&quot;, &quot;indhacinam&quot;, &quot;sinretrete&quot;, &quot;f__sinretr&quot;, &quot;indsinretr&quot;, &quot;poblsinobr&quot;, &quot;inundsi&quot;, &quot;inundno&quot;, &quot;inundtotal&quot;, &quot;basusi&quot;, &quot;basuno&quot;, &quot;basutotal&quot;, &quot;villasi&quot;, &quot;villano&quot;, &quot;villatotal&quot;, &quot;var\\u00a5n&quot;, &quot;mujer1&quot;, &quot;totalpob_1&quot;, &quot;f_pobinund&quot;, &quot;f_pobbasu&quot;, &quot;f_pobvilla&quot;, &quot;indinund&quot;, &quot;indbasu&quot;, &quot;indvilla&quot;, &quot;indpa&quot;, &quot;p1305&quot;, &quot;link2&quot;, &quot;f_sobsocia&quot;, &quot;indobsoc&quot;, &quot;icv2010&quot;, &quot;mergeicv&quot;, &quot;cprov&quot;, &quot;nprov&quot;, &quot;CicvNr&quot;, &quot;CicvNp&quot;, &quot;CicvNv&quot;, &quot;CrmaxNr&quot;, &quot;CrmaxNp&quot;, &quot;CrmaxNv&quot;, &quot;Crmaxp50Nr&quot;, &quot;Crmaxp50Np&quot;, &quot;Crmaxp50Nv&quot;, &quot;Crmaxp25Nr&quot;, &quot;Crmaxp25Np&quot;, &quot;Crmaxp25Nv&quot;, &quot;Crmaxp75Nr&quot;, &quot;Crmaxp75Np&quot;, &quot;Crmaxp75Nv&quot;, &quot;CicvPr&quot;, &quot;CicvPp&quot;, &quot;CicvPv&quot;, &quot;CrmaxPr&quot;, &quot;CrmaxPp&quot;, &quot;CrmaxPv&quot;, &quot;Crmaxp50Pr&quot;, &quot;Crmaxp50Pp&quot;, &quot;Crmaxp50Pv&quot;, &quot;Crmaxp25Pr&quot;, &quot;Crmaxp25Pp&quot;, &quot;Crmaxp25Pv&quot;, &quot;Crmaxp75Pr&quot;, &quot;Crmaxp75Pp&quot;, &quot;Crmaxp75Pv&quot;, &quot;tasa_activ&quot;, &quot;tasa_emple&quot;, &quot;tasa_desoc&quot;, &quot;total&quot;, &quot;total_val&quot;, &quot;con_nbi&quot;, &quot;sin_nbi&quot;, &quot;nbi_rc&quot;, &quot;nbi_rc_val&quot;, &quot;icpagNabs&quot;, &quot;CicpagNv&quot;, &quot;icpag&quot;];\n",
       "    let table = &#x27;&lt;table&gt;&#x27; +\n",
       "        String(\n",
       "        fields.map(\n",
       "        (v,i)=&gt;\n",
       "        `&lt;tr&gt;\n",
       "            &lt;th&gt;${aliases[i]}&lt;/th&gt;\n",
       "            \n",
       "            &lt;td&gt;${handleObject(layer.feature.properties[v])}&lt;/td&gt;\n",
       "        &lt;/tr&gt;`).join(&#x27;&#x27;))\n",
       "    +&#x27;&lt;/table&gt;&#x27;;\n",
       "    div.innerHTML=table;\n",
       "    \n",
       "    return div\n",
       "    }\n",
       "    ,{&quot;className&quot;: &quot;foliumtooltip&quot;, &quot;sticky&quot;: true});\n",
       "                     \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x29f7e3e7a00>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polygon.explore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GeoAxes' object has no attribute '_autoscaleXon'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mr:\\Tesis Nico\\Códigos\\scripts\\Testing - Deep Learning con MapTilesDownloader\\debug.ipynb Celda 6\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/r%3A/Tesis%20Nico/C%C3%B3digos/scripts/Testing%20-%20Deep%20Learning%20con%20MapTilesDownloader/debug.ipynb#X40sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39m# # Añade la máscara\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/r%3A/Tesis%20Nico/C%C3%B3digos/scripts/Testing%20-%20Deep%20Learning%20con%20MapTilesDownloader/debug.ipynb#X40sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# mask.difference(polygon).plot(ax=ax, facecolor='black', edgecolor='black', linewidth=0.0)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/r%3A/Tesis%20Nico/C%C3%B3digos/scripts/Testing%20-%20Deep%20Learning%20con%20MapTilesDownloader/debug.ipynb#X40sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m fig\u001b[39m.\u001b[39madd_axes(ax)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/r%3A/Tesis%20Nico/C%C3%B3digos/scripts/Testing%20-%20Deep%20Learning%20con%20MapTilesDownloader/debug.ipynb#X40sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m fig\u001b[39m.\u001b[39;49msavefig(\n\u001b[0;32m     <a href='vscode-notebook-cell:/r%3A/Tesis%20Nico/C%C3%B3digos/scripts/Testing%20-%20Deep%20Learning%20con%20MapTilesDownloader/debug.ipynb#X40sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mtext.jpg\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/r%3A/Tesis%20Nico/C%C3%B3digos/scripts/Testing%20-%20Deep%20Learning%20con%20MapTilesDownloader/debug.ipynb#X40sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     dpi\u001b[39m=\u001b[39;49mmy_dpi,\n\u001b[0;32m     <a href='vscode-notebook-cell:/r%3A/Tesis%20Nico/C%C3%B3digos/scripts/Testing%20-%20Deep%20Learning%20con%20MapTilesDownloader/debug.ipynb#X40sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\figure.py:3343\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[1;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[0;32m   3339\u001b[0m     \u001b[39mfor\u001b[39;00m ax \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes:\n\u001b[0;32m   3340\u001b[0m         stack\u001b[39m.\u001b[39menter_context(\n\u001b[0;32m   3341\u001b[0m             ax\u001b[39m.\u001b[39mpatch\u001b[39m.\u001b[39m_cm_set(facecolor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m, edgecolor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnone\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m-> 3343\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcanvas\u001b[39m.\u001b[39mprint_figure(fname, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\backend_bases.py:2366\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2362\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   2363\u001b[0m     \u001b[39m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[0;32m   2364\u001b[0m     \u001b[39m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[0;32m   2365\u001b[0m     \u001b[39mwith\u001b[39;00m cbook\u001b[39m.\u001b[39m_setattr_cm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure, dpi\u001b[39m=\u001b[39mdpi):\n\u001b[1;32m-> 2366\u001b[0m         result \u001b[39m=\u001b[39m print_method(\n\u001b[0;32m   2367\u001b[0m             filename,\n\u001b[0;32m   2368\u001b[0m             facecolor\u001b[39m=\u001b[39mfacecolor,\n\u001b[0;32m   2369\u001b[0m             edgecolor\u001b[39m=\u001b[39medgecolor,\n\u001b[0;32m   2370\u001b[0m             orientation\u001b[39m=\u001b[39morientation,\n\u001b[0;32m   2371\u001b[0m             bbox_inches_restore\u001b[39m=\u001b[39m_bbox_inches_restore,\n\u001b[0;32m   2372\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   2373\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   2374\u001b[0m     \u001b[39mif\u001b[39;00m bbox_inches \u001b[39mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\backend_bases.py:2232\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2228\u001b[0m     optional_kws \u001b[39m=\u001b[39m {  \u001b[39m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[0;32m   2229\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdpi\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfacecolor\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39medgecolor\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39morientation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   2230\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mbbox_inches_restore\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[0;32m   2231\u001b[0m     skip \u001b[39m=\u001b[39m optional_kws \u001b[39m-\u001b[39m {\u001b[39m*\u001b[39minspect\u001b[39m.\u001b[39msignature(meth)\u001b[39m.\u001b[39mparameters}\n\u001b[1;32m-> 2232\u001b[0m     print_method \u001b[39m=\u001b[39m functools\u001b[39m.\u001b[39mwraps(meth)(\u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: meth(\n\u001b[0;32m   2233\u001b[0m         \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m skip}))\n\u001b[0;32m   2234\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[0;32m   2235\u001b[0m     print_method \u001b[39m=\u001b[39m meth\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\backends\\backend_agg.py:526\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_jpg\u001b[1;34m(self, filename_or_obj, pil_kwargs)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprint_jpg\u001b[39m(\u001b[39mself\u001b[39m, filename_or_obj, \u001b[39m*\u001b[39m, pil_kwargs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    522\u001b[0m     \u001b[39m# savefig() has already applied savefig.facecolor; we now set it to\u001b[39;00m\n\u001b[0;32m    523\u001b[0m     \u001b[39m# white to make imsave() blend semi-transparent figures against an\u001b[39;00m\n\u001b[0;32m    524\u001b[0m     \u001b[39m# assumed white background.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m     \u001b[39mwith\u001b[39;00m mpl\u001b[39m.\u001b[39mrc_context({\u001b[39m\"\u001b[39m\u001b[39msavefig.facecolor\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mwhite\u001b[39m\u001b[39m\"\u001b[39m}):\n\u001b[1;32m--> 526\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_print_pil(filename_or_obj, \u001b[39m\"\u001b[39;49m\u001b[39mjpeg\u001b[39;49m\u001b[39m\"\u001b[39;49m, pil_kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\backends\\backend_agg.py:457\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[1;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_print_pil\u001b[39m(\u001b[39mself\u001b[39m, filename_or_obj, fmt, pil_kwargs, metadata\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    453\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[39m    Draw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[39m    *pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 457\u001b[0m     FigureCanvasAgg\u001b[39m.\u001b[39;49mdraw(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    458\u001b[0m     mpl\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mimsave(\n\u001b[0;32m    459\u001b[0m         filename_or_obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer_rgba(), \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39mfmt, origin\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mupper\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    460\u001b[0m         dpi\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure\u001b[39m.\u001b[39mdpi, metadata\u001b[39m=\u001b[39mmetadata, pil_kwargs\u001b[39m=\u001b[39mpil_kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\backends\\backend_agg.py:400\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[39m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[0;32m    397\u001b[0m \u001b[39mwith\u001b[39;00m RendererAgg\u001b[39m.\u001b[39mlock, \\\n\u001b[0;32m    398\u001b[0m      (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoolbar\u001b[39m.\u001b[39m_wait_cursor_for_draw_cm() \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoolbar\n\u001b[0;32m    399\u001b[0m       \u001b[39melse\u001b[39;00m nullcontext()):\n\u001b[1;32m--> 400\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mdraw(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrenderer)\n\u001b[0;32m    401\u001b[0m     \u001b[39m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[0;32m    402\u001b[0m     \u001b[39m# don't forget to call the superclass.\u001b[39;00m\n\u001b[0;32m    403\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mdraw()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39m@wraps\u001b[39m(draw)\n\u001b[0;32m     94\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdraw_wrapper\u001b[39m(artist, renderer, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 95\u001b[0m     result \u001b[39m=\u001b[39m draw(artist, renderer, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     96\u001b[0m     \u001b[39mif\u001b[39;00m renderer\u001b[39m.\u001b[39m_rasterizing:\n\u001b[0;32m     97\u001b[0m         renderer\u001b[39m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     73\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\figure.py:3140\u001b[0m, in \u001b[0;36mFigure.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3137\u001b[0m         \u001b[39m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[0;32m   3139\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[1;32m-> 3140\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[0;32m   3141\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[0;32m   3143\u001b[0m \u001b[39mfor\u001b[39;00m sfig \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubfigs:\n\u001b[0;32m   3144\u001b[0m     sfig\u001b[39m.\u001b[39mdraw(renderer)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[0;32m    130\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[1;32m--> 131\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[0;32m    132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    134\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\matplotlib\\artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[1;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     73\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\cartopy\\mpl\\geoaxes.py:552\u001b[0m, in \u001b[0;36mGeoAxes.draw\u001b[1;34m(self, renderer, **kwargs)\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_done_img_factory:\n\u001b[0;32m    550\u001b[0m     \u001b[39mfor\u001b[39;00m factory, factory_args, factory_kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_factories:\n\u001b[0;32m    551\u001b[0m         img, extent, origin \u001b[39m=\u001b[39m factory\u001b[39m.\u001b[39mimage_for_domain(\n\u001b[1;32m--> 552\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_extent_geom(factory\u001b[39m.\u001b[39;49mcrs), factory_args[\u001b[39m0\u001b[39m])\n\u001b[0;32m    553\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimshow(img, extent\u001b[39m=\u001b[39mextent, origin\u001b[39m=\u001b[39morigin,\n\u001b[0;32m    554\u001b[0m                     transform\u001b[39m=\u001b[39mfactory\u001b[39m.\u001b[39mcrs, \u001b[39m*\u001b[39mfactory_args[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    555\u001b[0m                     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs)\n\u001b[0;32m    556\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_done_img_factory \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\cartopy\\mpl\\geoaxes.py:821\u001b[0m, in \u001b[0;36mGeoAxes._get_extent_geom\u001b[1;34m(self, crs)\u001b[0m\n\u001b[0;32m    819\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_extent_geom\u001b[39m(\u001b[39mself\u001b[39m, crs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    820\u001b[0m     \u001b[39m# Perform the calculations for get_extent(), which just repackages it.\u001b[39;00m\n\u001b[1;32m--> 821\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhold_limits():\n\u001b[0;32m    822\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_autoscale_on():\n\u001b[0;32m    823\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mautoscale_view()\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\n\u001b[0;32m    134\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 135\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[0;32m    136\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    137\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgenerator didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt yield\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\cartopy\\mpl\\geoaxes.py:491\u001b[0m, in \u001b[0;36mGeoAxes.hold_limits\u001b[1;34m(self, hold)\u001b[0m\n\u001b[0;32m    488\u001b[0m data_lim \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataLim\u001b[39m.\u001b[39mfrozen()\u001b[39m.\u001b[39mget_points()\n\u001b[0;32m    489\u001b[0m view_lim \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mviewLim\u001b[39m.\u001b[39mfrozen()\u001b[39m.\u001b[39mget_points()\n\u001b[0;32m    490\u001b[0m other \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mignore_existing_data_limits,\n\u001b[1;32m--> 491\u001b[0m          \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autoscaleXon, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_autoscaleYon)\n\u001b[0;32m    492\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    493\u001b[0m     \u001b[39myield\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GeoAxes' object has no attribute '_autoscaleXon'"
     ]
    }
   ],
   "source": [
    "zoom = 18\n",
    "my_dpi = 96\n",
    "index = 0\n",
    "# Reduzco el polygono para que sea aprox una manzana\n",
    "polygon = random_point_from_geometry(icpag.iloc[index : index + 1, :])\n",
    "# polygon = icpag.iloc[index : index + 1, :]\n",
    "\n",
    "# Genero la máscara para el gráfico y obtengo el extent\n",
    "link = polygon.at[index, \"link\"]\n",
    "bbox = polygon.bounds\n",
    "geom = box(*bbox.values[0])\n",
    "mask = polygon.copy()\n",
    "mask[\"geometry\"] = geom\n",
    "\n",
    "# Gráfico\n",
    "# The pylab figure manager will be bypassed in this instance.\n",
    "# This means that `fig` will be garbage collected as you'd expect.\n",
    "fig = Figure(dpi=my_dpi, figsize=(512 / my_dpi, 512 / my_dpi), linewidth=0)\n",
    "ax = fig.add_axes(\n",
    "    [0, 0, 1, 1], projection=crs.epsg(3857), facecolor=\"black\"\n",
    ")\n",
    "\n",
    "# Limita la visualización a un área determinada\n",
    "ax.set_extent(\n",
    "    [bbox[\"minx\"], bbox[\"maxx\"], bbox[\"miny\"], bbox[\"maxy\"]],\n",
    "    crs=crs.epsg(3857),\n",
    ")\n",
    "\n",
    "# Agrego mapa de fondo\n",
    "ax.add_image(map_provider, zoom)\n",
    "\n",
    "# Quito bordes y grilla\n",
    "ax.set(frame_on=False)\n",
    "\n",
    "# # Añade la máscara\n",
    "# mask.difference(polygon).plot(ax=ax, facecolor='black', edgecolor='black', linewidth=0.0)\n",
    "fig.add_axes(ax)\n",
    "\n",
    "fig.savefig(\n",
    "    \"text.jpg\",\n",
    "    dpi=my_dpi,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def effnet_b0(kind=\"cla\") -> Sequential:\n",
    "    \"\"\"https://keras.io/api/applications/efficientnet_v2/#efficientnetv2s-function\"\"\"\n",
    "\n",
    "    assert kind in [\"cla\", \"reg\"], \"kind must be either cla or reg\"\n",
    "\n",
    "    model = models.Sequential()\n",
    "    if kind == \"cla\":\n",
    "        model.add(\n",
    "            EfficientNetB0(\n",
    "                weights=None,\n",
    "                include_top=True,\n",
    "                classes=10,\n",
    "                input_shape=(224, 224, 3),\n",
    "                pooling=\"max\",\n",
    "                classifier_activation=\"softmax\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if kind == \"reg\":\n",
    "        model.add(\n",
    "            EfficientNetB0(\n",
    "                weights=None,\n",
    "                include_top=False,\n",
    "                input_shape=(224, 224, 3),\n",
    "            )\n",
    "        )\n",
    "        model.add(layers.GlobalAveragePooling2D(name=\"avg_pool\"))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.4, name=\"top_dropout\"))\n",
    "        model.add(layers.Dense(1, activation=\"linear\", name=\"predictions\"))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_models = {\n",
    "    # \"rmax_d\": \"cla\",\n",
    "    # \"rmin_d\": \"cla\",\n",
    "    # \"icv2010_d\": \"cla\",\n",
    "    \"rmax\": \"reg\",\n",
    "    # \"rmin\": \"reg\",\n",
    "    # \"icv2010\": \"reg\",\n",
    "    # \"nbi_rc_val\": \"reg\",\n",
    "    # \"pm2\": \"reg\",\n",
    "    # \"viv_part\": \"reg\",\n",
    "}\n",
    "\n",
    "var = \"rmax\"\n",
    "kind = variable_models[var]\n",
    "model_function=effnet_b0(kind)\n",
    "lr=0.005  # lr=0.00005 para v0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(variable, kind, small_sample=False):\n",
    "    \"\"\"Accepts four Pandas DataFrames: all your data, the training, validation and test DataFrames. Creates and returns\n",
    "    keras ImageDataGenerat\n",
    "    ors. Within this function you can also visualize the augmentations of the ImageDataGenerators.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Your Pandas DataFrame containing all your data.\n",
    "    train : pd.DataFrame\n",
    "        Your Pandas DataFrame containing your training data.\n",
    "    val : pd.DataFrame\n",
    "        Your Pandas DataFrame containing your validation data.\n",
    "    test : pd.DataFrame\n",
    "        Your Pandas DataFrame containing your testing data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[tf.Dataset, tf.Dataset, tf.Dataset, dict]\n",
    "        A tuple containing the training, validation and test datasets, and a dictionary with each dataset's filepaths.        \n",
    "    \"\"\"\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    if small_sample:\n",
    "        print(\"Small sample not implemented yet\")\n",
    "    \n",
    "    ### prepare dataframes\n",
    "    # Open dataframe with files and labels\n",
    "    df = pd.read_parquet(rf\"{path_dataout}\\dataset_amba.parquet\")\n",
    "    df = df.dropna(subset=[variable] + [\"image\"]).reset_index(drop=True)\n",
    "    if small_sample:\n",
    "        df = df.sample(100, random_state=825).reset_index(drop=True)\n",
    "\n",
    "    # Train, validation and test split\n",
    "    train, test = train_test_split(df, test_size=0.2, shuffle=True, random_state=825)\n",
    "    test, val = train_test_split(test, test_size=0.5, shuffle=True, random_state=528)\n",
    "\n",
    "    assert pd.concat([train, test, val]).sort_index().equals(df)\n",
    "\n",
    "    ### dataframes to tf.data.Dataset\n",
    "    \n",
    "    def img_file_to_tensor(file, label):\n",
    "        def _img_file_to_tensor(file, label):\n",
    "            im = tf.image.decode_jpeg(tf.io.read_file(file), channels=3)\n",
    "            im = tf.image.resize(im, [224, 224])\n",
    "            im = tf.cast(im, tf.float32)\n",
    "            label = tf.cast(label, tf.float32)\n",
    "            return im, label\n",
    "\n",
    "        return tf.py_function(_img_file_to_tensor, [file, label], [tf.float32, tf.float32])\n",
    "    \n",
    "    # Create tf.data pipeline for each dataset\n",
    "    datasets = []\n",
    "    filenames_l = []\n",
    "    for dataframe in [train, test, val]:\n",
    "        # Get list of filenames and corresponding list of labels\n",
    "        filenames = tf.constant(dataframe[\"image\"].to_list())\n",
    "        if kind == \"reg\":\n",
    "            labels = tf.constant(dataframe[variable].to_list())\n",
    "        elif kind == \"cla\":\n",
    "            labels = tf.one_hot(\n",
    "                (df[variable] - 1).to_list(), 10\n",
    "            )  # Fist class corresponds to decile 1, etc.\n",
    "\n",
    "        # Create a dataset from the filenames and labels\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "        dataset = dataset.map(img_file_to_tensor) # Parse every image in the dataset using `map`\n",
    "        datasets += [dataset]\n",
    "        \n",
    "        # Store filenames for later use\n",
    "        filenames_l += [dataframe[\"image\"].to_list()]\n",
    "\n",
    "    train_dataset, test_dataset, val_dataset = datasets\n",
    "    filenames = {\"train\":filenames_l[0], \"test\":filenames_l[1], \"val\":filenames_l[2]}\n",
    "    \n",
    "    ### augmentations, batching and prefetching\n",
    "    # Create a data augmentation stage with horizontal flipping, rotations, zooms\n",
    "    data_augmentation = keras.Sequential(\n",
    "        [\n",
    "            layers.RandomFlip(\"horizontal_and_vertical\", seed=825, input_shape=(224, 224, 3)),\n",
    "            layers.RandomRotation(0.1, fill_mode=\"reflect\", seed=825),\n",
    "            layers.RandomZoom(0.1, 0.1, \"reflect\", seed=825),\n",
    "            layers.RandomContrast(0.1, seed=825),\n",
    "            layers.RandomBrightness(0.1, seed=825),\n",
    "        ],\n",
    "        name=\"data_augmentation\",\n",
    "    )\n",
    "    \n",
    "    # Prepare dataset for training\n",
    "    train_dataset = (\n",
    "        train_dataset.batch(16)\n",
    "        .map(lambda x, y: (data_augmentation(x), y))\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "    test_dataset = test_dataset.batch(128)\n",
    "    val_dataset = val_dataset.batch(128)\n",
    "\n",
    "    return train_dataset, test_dataset, val_dataset, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Open dataframe with files and labels\n",
    "df = pd.read_parquet(rf\"{path_dataout}\\dataset_amba.parquet\")\n",
    "df = df.dropna(subset=[variable] + [\"image\"]).reset_index(drop=True)\n",
    "if small_sample:\n",
    "    df = df.sample(1000, random_state=825).reset_index(drop=True)\n",
    "\n",
    "# Train, validation and test split\n",
    "train, test = train_test_split(df, test_size=0.2, shuffle=True, random_state=825)\n",
    "test, val = train_test_split(test, test_size=0.5, shuffle=True, random_state=528)\n",
    "\n",
    "assert pd.concat([train, test, val]).sort_index().equals(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################################\n",
      "Creating dataset for rmax (reg)\n",
      "#######################################################\n",
      "Small sample not implemented yet\n",
      "train_dataset: 80\n",
      "test_dataset: 10\n",
      "val_dataset: 10\n"
     ]
    }
   ],
   "source": [
    "print(\"#######################################################\")\n",
    "print(f\"Creating dataset for {var} ({kind})\")\n",
    "print(\"#######################################################\")\n",
    "pred_variable=var\n",
    "kind=kind\n",
    "small_sample=True\n",
    "\n",
    "model_name = f\"effnet_b0_{pred_variable}\"\n",
    "if kind == \"reg\":\n",
    "    loss = keras.losses.MeanSquaredError()\n",
    "    metrics = [keras.metrics.MeanAbsoluteError(), keras.metrics.MeanSquaredError()]\n",
    "\n",
    "elif kind == \"cla\":\n",
    "    loss = keras.losses.CategoricalCrossentropy()\n",
    "    metrics = [keras.metrics.CategoricalAccuracy(), keras.metrics.CategoricalCrossentropy()]\n",
    "\n",
    "train_dataset, test_dataset, val_dataset, filenames = create_datasets(\n",
    "    variable=pred_variable,\n",
    "    kind=kind,\n",
    "    small_sample=small_sample,\n",
    ")\n",
    "print(\"train_dataset:\", len(list(train_dataset.unbatch())))\n",
    "print(\"test_dataset:\", len(list(test_dataset.unbatch())))\n",
    "print(\"val_dataset:\", len(list(val_dataset.unbatch())))\n",
    "\n",
    "train_generator=train_dataset\n",
    "validation_generator=val_dataset\n",
    "test_generator=test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######################################################\n",
      "Running model for rmax (reg)\n",
      "#######################################################\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb0 (Functional)  (None, 7, 7, 1280)       4049571   \n",
      "                                                                 \n",
      " avg_pool (GlobalAveragePool  (None, 1280)             0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 1280)             5120      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " top_dropout (Dropout)       (None, 1280)              0         \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1)                 1281      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,055,972\n",
      "Trainable params: 4,011,389\n",
      "Non-trainable params: 44,583\n",
      "_________________________________________________________________\n",
      "5/5 [==============================] - 74s 2s/step - loss: 4300.0586 - mean_absolute_error: 28.1070 - mean_squared_error: 4300.0586 - val_loss: 8210194413935468216320.0000 - val_mean_absolute_error: 89649291264.0000 - val_mean_squared_error: 8210194413935468216320.0000\n"
     ]
    }
   ],
   "source": [
    "#### FIT\n",
    "print(\"#######################################################\")\n",
    "print(f\"Running model for {var} ({kind})\")\n",
    "print(\"#######################################################\")\n",
    "\n",
    "callbacks = effnet_model_tf_copy.get_callbacks(model_name, loss)\n",
    "model = model_function\n",
    "model.summary()\n",
    "plot_model(model, to_file=model_name + \".png\", show_shapes=True)\n",
    "\n",
    "radam = tfa.optimizers.RectifiedAdam(learning_rate=lr)\n",
    "ranger = tfa.optimizers.Lookahead(radam, sync_period=6, slow_step_size=0.5)\n",
    "optimizer = ranger\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=1,\n",
    "    validation_data=validation_generator,\n",
    "    shuffle=True,\n",
    "    callbacks=callbacks,\n",
    "    workers=8,  # adjust this according to the number of CPU cores of your machine\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 3s 33ms/step - loss: 9872125696276657340416.0000 - mean_absolute_error: 97152294912.0000 - mean_squared_error: 9872125696276657340416.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9.872125696276657e+21, 97152294912.0, 9.872125696276657e+21]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(\n",
    "    dataset,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'prediction_tools' from 'r:\\\\Tesis Nico\\\\Códigos\\\\scripts\\\\Testing - Deep Learning con MapTilesDownloader\\\\prediction_tools.py'>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(prediction_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 93ms/step\n"
     ]
    }
   ],
   "source": [
    "# plot_results(small_cnn_history, mean_baseline)\n",
    "predicted_array = prediction_tools.get_predicted_values(model, test_dataset, kind=\"reg\")\n",
    "real_array = prediction_tools.get_real_values(test_dataset.unbatch())\n",
    "\n",
    "# for norm in [\"pred\", \"true\"]:\n",
    "#     prediction_tools.plot_confusion_matrix(\n",
    "#         real_array,\n",
    "#         predicted_array,\n",
    "#         model_name,\n",
    "#         normalize=norm,\n",
    "#     )\n",
    "#     fig.savefig(f\"{path_figures}/confusion_matrix_{model_name}_{norm}.png\")\n",
    "\n",
    "# Creo dataframe para exportar:\n",
    "d = {\"filename\": filenames['test'],\"real\": real_array, \"pred\": predicted_array.flatten()}\n",
    "pd.DataFrame(data=d).to_parquet(f\"{path_dataout}/preds_{model_name}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>provincia</th>\n",
       "      <th>eph_codagl</th>\n",
       "      <th>eph_aglome</th>\n",
       "      <th>codaglo</th>\n",
       "      <th>aglomerado</th>\n",
       "      <th>aglo_eph</th>\n",
       "      <th>AMBA_legal</th>\n",
       "      <th>rmin</th>\n",
       "      <th>rmax</th>\n",
       "      <th>...</th>\n",
       "      <th>viv_part</th>\n",
       "      <th>indvilla</th>\n",
       "      <th>icv2010</th>\n",
       "      <th>nbi_rc_val</th>\n",
       "      <th>icpag</th>\n",
       "      <th>rmax_d</th>\n",
       "      <th>icv2010_d</th>\n",
       "      <th>rmin_d</th>\n",
       "      <th>fuente</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>020072103</td>\n",
       "      <td>Ciudad Autónoma de Buenos Aires</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CABA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Gran Buenos Aires</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.926784</td>\n",
       "      <td>0.743279</td>\n",
       "      <td>...</td>\n",
       "      <td>512</td>\n",
       "      <td>0.972679</td>\n",
       "      <td>0.852608</td>\n",
       "      <td>0.078522</td>\n",
       "      <td>0.91</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>ESRI</td>\n",
       "      <td>R:/Tesis Nico/Códigos/data/data_in/Maps_and_ES...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         link                        provincia  eph_codagl eph_aglome  \\\n",
       "44  020072103  Ciudad Autónoma de Buenos Aires         1.0       CABA   \n",
       "\n",
       "    codaglo         aglomerado  aglo_eph  AMBA_legal      rmin      rmax  ...  \\\n",
       "44      1.0  Gran Buenos Aires         1           1  0.926784  0.743279  ...   \n",
       "\n",
       "    viv_part  indvilla   icv2010  nbi_rc_val  icpag  rmax_d  icv2010_d  \\\n",
       "44       512  0.972679  0.852608    0.078522   0.91       9         10   \n",
       "\n",
       "    rmin_d  fuente                                              image  \n",
       "44      10    ESRI  R:/Tesis Nico/Códigos/data/data_in/Maps_and_ES...  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.link == '020072103']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7432791"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=d).at[0, \"real\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7432791,\n",
       " 0.4564761,\n",
       " 0.3996914,\n",
       " 0.12278092,\n",
       " 0.24094415,\n",
       " 0.8243184,\n",
       " 0.13266665,\n",
       " 0.09695727,\n",
       " 0.5302392,\n",
       " 0.24094415]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[lab.numpy() for im, lab in test_dataset.unbatch().take(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mr:\\Tesis Nico\\Códigos\\scripts\\Testing - Deep Learning con MapTilesDownloader\\03 notebook.ipynb Celda 10\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/r%3A/Tesis%20Nico/C%C3%B3digos/scripts/Testing%20-%20Deep%20Learning%20con%20MapTilesDownloader/03%20notebook.ipynb#X52sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pd\u001b[39m.\u001b[39;49mDataFrame(data\u001b[39m=\u001b[39;49md)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:663\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    657\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[0;32m    658\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    659\u001b[0m     )\n\u001b[0;32m    661\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    662\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 663\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[0;32m    664\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[0;32m    665\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmrecords\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\internals\\construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[1;32m--> 493\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\internals\\construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    116\u001b[0m     \u001b[39m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m         index \u001b[39m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    119\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\internals\\construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    664\u001b[0m lengths \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(raw_lengths))\n\u001b[0;32m    665\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(lengths) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 666\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAll arrays must be of the same length\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    668\u001b[0m \u001b[39mif\u001b[39;00m have_dicts:\n\u001b[0;32m    669\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    670\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    671\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mr:\\Tesis Nico\\Códigos\\scripts\\Testing - Deep Learning con MapTilesDownloader\\03 notebook.ipynb Celda 11\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/r%3A/Tesis%20Nico/C%C3%B3digos/scripts/Testing%20-%20Deep%20Learning%20con%20MapTilesDownloader/03%20notebook.ipynb#X43sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m d \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mfile\u001b[39m\u001b[39m\"\u001b[39m:filenames\u001b[39m.\u001b[39mnumpy(), \u001b[39m\"\u001b[39m\u001b[39mreal\u001b[39m\u001b[39m\"\u001b[39m: predicted_array\u001b[39m.\u001b[39mflatten(), \u001b[39m\"\u001b[39m\u001b[39mpred\u001b[39m\u001b[39m\"\u001b[39m: real_array}\n\u001b[1;32m----> <a href='vscode-notebook-cell:/r%3A/Tesis%20Nico/C%C3%B3digos/scripts/Testing%20-%20Deep%20Learning%20con%20MapTilesDownloader/03%20notebook.ipynb#X43sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pd\u001b[39m.\u001b[39;49mDataFrame(data\u001b[39m=\u001b[39;49md)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\frame.py:663\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    657\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[0;32m    658\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    659\u001b[0m     )\n\u001b[0;32m    661\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    662\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 663\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[0;32m    664\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[0;32m    665\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmrecords\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\internals\\construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[1;32m--> 493\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\internals\\construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    116\u001b[0m     \u001b[39m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m         index \u001b[39m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    119\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\internals\\construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    664\u001b[0m lengths \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(raw_lengths))\n\u001b[0;32m    665\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(lengths) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 666\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAll arrays must be of the same length\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    668\u001b[0m \u001b[39mif\u001b[39;00m have_dicts:\n\u001b[0;32m    669\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    670\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    671\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "d = {\"file\":filenames.numpy(), \"real\": predicted_array.flatten(), \"pred\": real_array}\n",
    "pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100,), dtype=string, numpy=\n",
       "array([b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_060910803.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064415910.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_065152107.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020121004.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_063711210.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_064416207.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_063712213.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_020142607.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_020110211.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020022201.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020101311.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_067560701.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_020151906.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064904003.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064101109.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_067491312.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_066381805.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_020010914.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_066380513.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_063710708.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_067490202.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020052201.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_066584412.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020140704.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064343206.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_065151603.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_062741210.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064279715.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064970604.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_062742010.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020111705.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064341602.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_066580207.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_065390405.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_067490913.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_067601712.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_064272702.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_064270408.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_060910203.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020130601.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064412912.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_068401202.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_067600110.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_064275509.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_020072103.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_064900514.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_060352907.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_060912001.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_063710314.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_065680908.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_060283702.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064416103.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_064274606.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020100103.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020031203.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020020303.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_066580815.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064416006.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020143102.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064121409.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020100709.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_064080805.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_064274604.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020140509.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_063711003.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064273003.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020011206.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064275611.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_065680803.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_068400608.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_068402405.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020100512.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020052209.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_066580812.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_067601203.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_064413607.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_060283306.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_062700814.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_065390303.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_060352103.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_020030903.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_060350605.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020140808.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_060281303.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_065601504.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_020051403.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_067600802.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064273802.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_068611410.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_062740209.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064342207.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020070104.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_060283702.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064271110.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_068610611.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064903905.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064901405.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064413107.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_060350608.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_064414205.jpeg'],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_060910803.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064415910.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_065152107.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020121004.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_063711210.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_064416207.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_063712213.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_020142607.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_020110211.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020022201.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020101311.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_067560701.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_020151906.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064904003.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064101109.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_067491312.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_066381805.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_020010914.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_066380513.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_063710708.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_067490202.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020052201.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_066584412.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020140704.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064343206.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_065151603.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_062741210.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064279715.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064970604.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_062742010.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020111705.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064341602.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_066580207.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_065390405.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_067490913.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_067601712.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_064272702.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_064270408.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_060910203.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020130601.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064412912.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_068401202.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_067600110.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_064275509.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_020072103.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_064900514.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_060352907.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_060912001.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_063710314.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_065680908.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_060283702.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064416103.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_064274606.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020100103.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020031203.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020020303.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_066580815.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064416006.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020143102.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064121409.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020100709.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_064080805.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_064274604.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020140509.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_063711003.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064273003.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020011206.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064275611.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_065680803.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_068400608.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_068402405.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020100512.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020052209.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_066580812.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_067601203.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_064413607.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_060283306.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_062700814.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_065390303.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_060352103.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_020030903.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_060350605.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020140808.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_060281303.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_065601504.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_020051403.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_067600802.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064273802.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_068611410.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_062740209.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064342207.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_020070104.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_060283702.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064271110.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_068610611.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064903905.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064901405.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_064413107.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/ESRI_060350608.jpeg',\n",
       "       b'R:/Tesis Nico/C\\xc3\\xb3digos/data/data_in/Maps_and_ESRI/images_512/GMaps_064414205.jpeg'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset element_spec=(TensorSpec(shape=<unknown>, dtype=tf.float32, name=None), TensorSpec(shape=<unknown>, dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.929386e+10</td>\n",
       "      <td>0.693946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.215763e+10</td>\n",
       "      <td>0.202322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.898093e+10</td>\n",
       "      <td>0.553656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.630018e+10</td>\n",
       "      <td>0.647995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.515376e+10</td>\n",
       "      <td>0.775665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-2.979884e+10</td>\n",
       "      <td>0.240944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-2.380503e+10</td>\n",
       "      <td>0.623621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-3.228143e+10</td>\n",
       "      <td>0.339379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-2.317129e+10</td>\n",
       "      <td>0.399691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-2.515627e+10</td>\n",
       "      <td>0.293619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           real      pred\n",
       "0 -2.929386e+10  0.693946\n",
       "1 -2.215763e+10  0.202322\n",
       "2 -1.898093e+10  0.553656\n",
       "3 -2.630018e+10  0.647995\n",
       "4 -2.515376e+10  0.775665\n",
       "5 -2.979884e+10  0.240944\n",
       "6 -2.380503e+10  0.623621\n",
       "7 -3.228143e+10  0.339379\n",
       "8 -2.317129e+10  0.399691\n",
       "9 -2.515627e+10  0.293619"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5208616,\n",
       " 0.67933846,\n",
       " 0.55365634,\n",
       " 0.44063377,\n",
       " 0.3996914,\n",
       " 0.450572,\n",
       " 0.76165307,\n",
       " 0.12877834,\n",
       " 0.33937907,\n",
       " 0.46513474]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.2157631e+10, -1.9885482e+10, -1.8980925e+10, -2.4526674e+10,\n",
       "       -2.7393741e+10, -2.5056664e+10, -9.0328556e+09, -2.5156272e+10,\n",
       "       -2.3261700e+10, -3.2042357e+10], dtype=float32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_array.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -2.215763e+10\n",
       "1   -1.988548e+10\n",
       "2   -1.898093e+10\n",
       "3   -2.452667e+10\n",
       "4   -2.739374e+10\n",
       "5   -2.505666e+10\n",
       "6   -9.032856e+09\n",
       "7   -2.515627e+10\n",
       "8   -2.326170e+10\n",
       "9   -3.204236e+10\n",
       "dtype: float32"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(predicted_array.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.2157631e+10, -1.9885482e+10, -1.8980925e+10, -2.4526674e+10,\n",
       "        -2.7393741e+10, -2.5056664e+10, -9.0328556e+09, -2.5156272e+10,\n",
       "        -2.3261700e+10, -3.2042357e+10]], dtype=float32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_array.reshape(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "% tensorboad\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
